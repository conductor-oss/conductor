{
  "properties": [
    {
      "name": "conductor.metrics-logger.reportPeriodSeconds",
      "type": "java.lang.Long",
      "description": "The interval (in seconds) at which the metrics will be reported into the log stream by the metrics-logger."
    },
    {
      "name": "conductor.tasks.http.readTimeout",
      "type": "java.lang.Integer",
      "description": "The read timeout of the underlying HttpClient used by the HTTP task."
    },
    {
      "name": "conductor.tasks.http.connectTimeout",
      "type": "java.lang.Integer",
      "description": "The connection timeout of the underlying HttpClient used by the HTTP task."
    },
    {
      "name": "conductor.tasks.kafka-publish.requestTimeoutMs",
      "type": "java.lang.String",
      "description": "The request.timeout.ms value that the kafka producer is configured with in the KAFKA_PUBLISH task."
    },
    {
      "name": "conductor.tasks.kafka-publish.maxBlockMs",
      "type": "java.lang.String",
      "description": "The max.block.ms value that the kafka producer is configured with in the KAFKA_PUBLISH task."
    },
    {
      "name": "conductor.tasks.kafka-publish.cacheSize",
      "type": "java.lang.Integer",
      "description": "The maximum number of entries permitted in the in-memory cache used by the KAFKA_PUBLISH task."
    },
    {
      "name": "conductor.tasks.kafka-publish.cacheTimeMs",
      "type": "java.lang.Integer",
      "description": "The duration after which a cached entry will be removed from the in-memory cache used by the KAFKA_PUBLISH task."
    },
    {
      "name": "conductor.workflow-status-listener.type",
      "type": "java.lang.String",
      "description": "The implementation of the workflow status listener to be used."
    },
    {
      "name": "conductor.workflow-execution-lock.type",
      "type": "java.lang.String",
      "description": "The implementation of the workflow execution lock to be used.",
      "defaultValue": "noop_lock"
    },
    {
      "name": "conductor.event-queues.sqs.enabled",
      "type": "java.lang.Boolean",
      "description": "Enable the use of AWS SQS implementation to provide queues for consuming events.",
      "sourceType": "com.netflix.conductor.contribs.queue.sqs.config.SQSEventQueueConfiguration"
    },
    {
      "name": "conductor.event-queues.amqp.enabled",
      "type": "java.lang.Boolean",
      "description": "Enable the use of RabbitMQ implementation to provide queues for consuming events.",
      "sourceType": "com.netflix.conductor.contribs.queue.amqp.config.AMQPEventQueueConfiguration"
    },
    {
      "name": "conductor.event-queues.nats.enabled",
      "type": "java.lang.Boolean",
      "description": "Enable the use of NATS implementation to provide queues for consuming events.",
      "sourceType": "com.netflix.conductor.contribs.queue.nats.config.NATSConfiguration"
    },
    {
      "name": "conductor.event-queues.nats-stream.enabled",
      "type": "java.lang.Boolean",
      "description": "Enable the use of NATS Streaming implementation to provide queues for consuming events.",
      "sourceType": "com.netflix.conductor.contribs.queue.nats.config.NATSStreamConfiguration"
    },
    {
      "name": "conductor.event-queues.kafka.enabled",
      "type": "java.lang.Boolean",
      "description": "Enable the use of Kafka implementation to provide queues for consuming events.",
      "sourceType": "com.netflix.conductor.event-queue.kafkaeq.config.KafkaEventQueueConfiguration"
    },
    {
      "name": "conductor.default-event-queue.type",
      "type": "java.lang.String",
      "description": "The default event queue type to listen on for the WAIT task."
    }
  ],
  "hints": [
    {
      "name": "conductor.workflow-status-listener.type",
      "values": [
        {
          "value": "stub",
          "description": "Use the no-op implementation of the workflow status listener."
        },
        {
          "value": "archive",
          "description": "Use then archive implementation which immediately archives the workflow upon termination or completion as the workflow status listener."
        },
        {
          "value": "queue_publisher",
          "description": "Use the publisher implementation which publishes a message to the underlying queue implementation upon termination or completion as the workflow status listener."
        }
      ]
    },
    {
      "name": "conductor.default-event-queue.type",
      "values": [
        {
          "value": "sqs",
          "description": "Use AWS SQS as the event queue to listen on for the WAIT task."
        },
        {
          "value": "amqp",
          "description": "Use RabbitMQ as the event queue to listen on for the WAIT task."
        },
        {
          "value": "nats_stream",
          "description": "Use NATS Stream as the event queue to listen on for the WAIT task."
        },
        {
          "value": "kafka",
          "description": "Use Kafka as the event queue to listen on for the WAIT task."
        }
      ]
    },
    {
      "name": "conductor.workflow-execution-lock.type",
      "values": [
        {
          "value": "noop_lock",
          "description": "Use the no-op implementation as the lock provider."
        },
        {
          "value": "local_only",
          "description": "Use the local in-memory cache based implementation as the lock provider."
        },
        {
          "value": "redis",
          "description": "Use the redis-lock implementation as the lock provider."
        },
        {
          "value": "zookeeper",
          "description": "Use the zookeeper-lock implementation as the lock provider."
        }
      ]
    }
  ]
}
