{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Conductor is a Workflow Orchestration engine that runs in the cloud. Motivation We built Conductor to help us orchestrate microservices based process flows at Netflix with the following features: A distributed server ecosystem, which stores workflow state information efficiently. Allow creation of process / business flows in which each individual task can be implemented by the same / different microservices. A JSON DSL based blueprint defines the execution flow. Provide visibility and traceability into the these process flows. Simple interface to connect workers, which execute the tasks in workflows. Full operational control over workflows with the ability to pause, resume, restart, retry and terminate. Allow greater reuse of existing microservices providing an easier path for onboarding. User interface to visualize, replay and search the process flows. Ability to scale to millions of concurrently running process flows. Backed by a queuing service abstracted from the clients. Be able to operate on HTTP or other transports e.g. gRPC. Event handlers to control workflows via external actions. Client implementations in Java, Python and other languages. Various configurable properties with sensible defaults to fine tune workflow and task executions like rate limiting, concurrent execution limits etc. Why not peer to peer choreography? With peer to peer task choreography, we found it was harder to scale with growing business needs and complexities. Pub/sub model worked for simplest of the flows, but quickly highlighted some of the issues associated with the approach: Process flows are \u201cembedded\u201d within the code of multiple application. Often, there is tight coupling and assumptions around input/output, SLAs etc, making it harder to adapt to changing needs. Almost no way to systematically answer \u201cHow much are we done with process X\u201d?","title":"Introduction"},{"location":"#motivation","text":"We built Conductor to help us orchestrate microservices based process flows at Netflix with the following features: A distributed server ecosystem, which stores workflow state information efficiently. Allow creation of process / business flows in which each individual task can be implemented by the same / different microservices. A JSON DSL based blueprint defines the execution flow. Provide visibility and traceability into the these process flows. Simple interface to connect workers, which execute the tasks in workflows. Full operational control over workflows with the ability to pause, resume, restart, retry and terminate. Allow greater reuse of existing microservices providing an easier path for onboarding. User interface to visualize, replay and search the process flows. Ability to scale to millions of concurrently running process flows. Backed by a queuing service abstracted from the clients. Be able to operate on HTTP or other transports e.g. gRPC. Event handlers to control workflows via external actions. Client implementations in Java, Python and other languages. Various configurable properties with sensible defaults to fine tune workflow and task executions like rate limiting, concurrent execution limits etc. Why not peer to peer choreography? With peer to peer task choreography, we found it was harder to scale with growing business needs and complexities. Pub/sub model worked for simplest of the flows, but quickly highlighted some of the issues associated with the approach: Process flows are \u201cembedded\u201d within the code of multiple application. Often, there is tight coupling and assumptions around input/output, SLAs etc, making it harder to adapt to changing needs. Almost no way to systematically answer \u201cHow much are we done with process X\u201d?","title":"Motivation"},{"location":"apispec/","text":"Task Workflow Metadata Endpoint Description Input GET /metadata/taskdefs Get all the task definitions n/a GET /metadata/taskdefs/{taskType} Retrieve task definition Task Name POST /metadata/taskdefs Register new task definitions List of Task Definitions PUT /metadata/taskdefs Update a task definition A Task Definition DELETE /metadata/taskdefs/{taskType} Delete a task definition Task Name GET /metadata/workflow Get all the workflow definitions n/a POST /metadata/workflow Register new workflow Workflow Definition PUT /metadata/workflow Register/Update new workflows List of Workflow Definition GET /metadata/workflow/{name}?version= Get the workflow definitions workflow name, version (optional) Start A Workflow With Input only See Start Workflow Request . Output Id of the workflow (GUID) With Input and Task Domains POST /workflow { //JSON payload for Start workflow request } Start workflow request JSON for start workflow request { name : myWorkflow , // Name of the workflow version : 1, // Version \u201ccorrelationId\u201d: \u201ccorr1\u201d, // correlation Id input : { // Input map. }, taskToDomain : { // Task to domain map } } Output Id of the workflow (GUID) Retrieve Workflows Endpoint Description GET /workflow/{workflowId}?includeTasks=true|false Get Workflow State by workflow Id. If includeTasks is set, then also includes all the tasks executed and scheduled. GET /workflow/running/{name} Get all the running workflows of a given type GET /workflow/running/{name}/correlated/{correlationId}?includeClosed=true|false includeTasks=true|false Get all the running workflows filtered by correlation Id. If includeClosed is set, also includes workflows that have completed running. GET /workflow/search Search for workflows. See Below. Search for Workflows Conductor uses Elasticsearch for indexing workflow execution and is used by search APIs. GET /workflow/search?start= size= sort= freeText= query= Parameter Description start Page number. Defaults to 0 size Number of results to return sort Sorting. Format is: ASC: fieldname or DESC: fieldname to sort in ascending or descending order by a field freeText Elasticsearch supported query. e.g. workflowType:\"name_of_workflow\" query SQL like where clause. e.g. workflowType = 'name_of_workflow'. Optional if freeText is provided. Output Search result as described below: { totalHits : 0 , results : [ { workflowType : string , version : 0 , workflowId : string , correlationId : string , startTime : string , updateTime : string , endTime : string , status : RUNNING , input : string , output : string , reasonForIncompletion : string , executionTime : 0 , event : string } ] } Manage Workflows Endpoint Description PUT /workflow/{workflowId}/pause Pause. No further tasks will be scheduled until resumed. Currently running tasks are not paused. PUT /workflow/{workflowId}/resume Resume normal operations after a pause. POST /workflow/{workflowId}/rerun See Below. POST /workflow/{workflowId}/restart Restart workflow execution from the start. Current execution history is wiped out. POST /workflow/{workflowId}/retry Retry the last failed task. PUT /workflow/{workflowId}/skiptask/{taskReferenceName} See below. DELETE /workflow/{workflowId} Terminates the running workflow. DELETE /workflow/{workflowId}/remove Deletes the workflow from system. Use with caution. Rerun Re-runs a completed workflow from a specific task. POST /workflow/{workflowId}/rerun { reRunFromWorkflowId : string , workflowInput : {}, reRunFromTaskId : string , taskInput : {} } Skip Task Skips a task execution (specified as taskReferenceName parameter) in a running workflow and continues forward. Optionally updating task's input and output as specified in the payload. PUT /workflow/{workflowId}/skiptask/{taskReferenceName}?workflowId= taskReferenceName= { taskInput : {}, taskOutput : {} } Manage Tasks Endpoint Description GET /tasks/{taskId} Get task details. GET /tasks/queue/all List the pending task sizes. GET /tasks/queue/all/verbose Same as above, includes the size per shard GET /tasks/queue/sizes?taskType= taskType= taskType Return the size of pending tasks for given task types Polling, Ack and Update Task These are critical endpoints used to poll for task, send ack (after polling) and finally updating the task result by worker. Endpoint Description GET /tasks/poll/{taskType}?workerid= domain= Poll for a task. workerid identifies the worker that polled for the job and domain allows the poller to poll for a task in a specific domain GET /tasks/poll/batch/{taskType}?count= timeout= workerid= domain Poll for a task in a batch specified by count . This is a long poll and the connection will wait until timeout or if there is at-least 1 item available, whichever comes first. workerid identifies the worker that polled for the job and domain allows the poller to poll for a task in a specific domain POST /tasks Update the result of task execution. See the schema below. POST /tasks/{taskId}/ack Acknowledges the task received AFTER poll by worker. Schema for updating Task Result { workflowInstanceId : Workflow Instance Id , taskId : ID of the task to be updated , reasonForIncompletion : If failed, reason for failure , callbackAfterSeconds : 0 , status : IN_PROGRESS|FAILED|COMPLETED , outputData : { //JSON document representing Task execution output } } Acknowledging tasks after poll If the worker fails to ack the task after polling, the task is re-queued and put back in queue and is made available during subsequent poll.","title":"API Specification"},{"location":"apispec/#task-workflow-metadata","text":"Endpoint Description Input GET /metadata/taskdefs Get all the task definitions n/a GET /metadata/taskdefs/{taskType} Retrieve task definition Task Name POST /metadata/taskdefs Register new task definitions List of Task Definitions PUT /metadata/taskdefs Update a task definition A Task Definition DELETE /metadata/taskdefs/{taskType} Delete a task definition Task Name GET /metadata/workflow Get all the workflow definitions n/a POST /metadata/workflow Register new workflow Workflow Definition PUT /metadata/workflow Register/Update new workflows List of Workflow Definition GET /metadata/workflow/{name}?version= Get the workflow definitions workflow name, version (optional)","title":"Task &amp; Workflow Metadata"},{"location":"apispec/#start-a-workflow","text":"","title":"Start A Workflow"},{"location":"apispec/#with-input-only","text":"See Start Workflow Request .","title":"With Input only"},{"location":"apispec/#output","text":"Id of the workflow (GUID)","title":"Output"},{"location":"apispec/#with-input-and-task-domains","text":"POST /workflow { //JSON payload for Start workflow request }","title":"With Input and Task Domains"},{"location":"apispec/#start-workflow-request","text":"JSON for start workflow request { name : myWorkflow , // Name of the workflow version : 1, // Version \u201ccorrelationId\u201d: \u201ccorr1\u201d, // correlation Id input : { // Input map. }, taskToDomain : { // Task to domain map } }","title":"Start workflow request"},{"location":"apispec/#output_1","text":"Id of the workflow (GUID)","title":"Output"},{"location":"apispec/#retrieve-workflows","text":"Endpoint Description GET /workflow/{workflowId}?includeTasks=true|false Get Workflow State by workflow Id. If includeTasks is set, then also includes all the tasks executed and scheduled. GET /workflow/running/{name} Get all the running workflows of a given type GET /workflow/running/{name}/correlated/{correlationId}?includeClosed=true|false includeTasks=true|false Get all the running workflows filtered by correlation Id. If includeClosed is set, also includes workflows that have completed running. GET /workflow/search Search for workflows. See Below.","title":"Retrieve Workflows"},{"location":"apispec/#search-for-workflows","text":"Conductor uses Elasticsearch for indexing workflow execution and is used by search APIs. GET /workflow/search?start= size= sort= freeText= query= Parameter Description start Page number. Defaults to 0 size Number of results to return sort Sorting. Format is: ASC: fieldname or DESC: fieldname to sort in ascending or descending order by a field freeText Elasticsearch supported query. e.g. workflowType:\"name_of_workflow\" query SQL like where clause. e.g. workflowType = 'name_of_workflow'. Optional if freeText is provided.","title":"Search for Workflows"},{"location":"apispec/#output_2","text":"Search result as described below: { totalHits : 0 , results : [ { workflowType : string , version : 0 , workflowId : string , correlationId : string , startTime : string , updateTime : string , endTime : string , status : RUNNING , input : string , output : string , reasonForIncompletion : string , executionTime : 0 , event : string } ] }","title":"Output"},{"location":"apispec/#manage-workflows","text":"Endpoint Description PUT /workflow/{workflowId}/pause Pause. No further tasks will be scheduled until resumed. Currently running tasks are not paused. PUT /workflow/{workflowId}/resume Resume normal operations after a pause. POST /workflow/{workflowId}/rerun See Below. POST /workflow/{workflowId}/restart Restart workflow execution from the start. Current execution history is wiped out. POST /workflow/{workflowId}/retry Retry the last failed task. PUT /workflow/{workflowId}/skiptask/{taskReferenceName} See below. DELETE /workflow/{workflowId} Terminates the running workflow. DELETE /workflow/{workflowId}/remove Deletes the workflow from system. Use with caution.","title":"Manage Workflows"},{"location":"apispec/#rerun","text":"Re-runs a completed workflow from a specific task. POST /workflow/{workflowId}/rerun { reRunFromWorkflowId : string , workflowInput : {}, reRunFromTaskId : string , taskInput : {} }","title":"Rerun"},{"location":"apispec/#skip-task","text":"Skips a task execution (specified as taskReferenceName parameter) in a running workflow and continues forward. Optionally updating task's input and output as specified in the payload. PUT /workflow/{workflowId}/skiptask/{taskReferenceName}?workflowId= taskReferenceName= { taskInput : {}, taskOutput : {} }","title":"Skip Task"},{"location":"apispec/#manage-tasks","text":"Endpoint Description GET /tasks/{taskId} Get task details. GET /tasks/queue/all List the pending task sizes. GET /tasks/queue/all/verbose Same as above, includes the size per shard GET /tasks/queue/sizes?taskType= taskType= taskType Return the size of pending tasks for given task types","title":"Manage Tasks"},{"location":"apispec/#polling-ack-and-update-task","text":"These are critical endpoints used to poll for task, send ack (after polling) and finally updating the task result by worker. Endpoint Description GET /tasks/poll/{taskType}?workerid= domain= Poll for a task. workerid identifies the worker that polled for the job and domain allows the poller to poll for a task in a specific domain GET /tasks/poll/batch/{taskType}?count= timeout= workerid= domain Poll for a task in a batch specified by count . This is a long poll and the connection will wait until timeout or if there is at-least 1 item available, whichever comes first. workerid identifies the worker that polled for the job and domain allows the poller to poll for a task in a specific domain POST /tasks Update the result of task execution. See the schema below. POST /tasks/{taskId}/ack Acknowledges the task received AFTER poll by worker.","title":"Polling, Ack and Update Task"},{"location":"apispec/#schema-for-updating-task-result","text":"{ workflowInstanceId : Workflow Instance Id , taskId : ID of the task to be updated , reasonForIncompletion : If failed, reason for failure , callbackAfterSeconds : 0 , status : IN_PROGRESS|FAILED|COMPLETED , outputData : { //JSON document representing Task execution output } } Acknowledging tasks after poll If the worker fails to ack the task after polling, the task is re-queued and put back in queue and is made available during subsequent poll.","title":"Schema for updating Task Result"},{"location":"architecture/","text":"High Level Architecture The API and storage layers are pluggable and provide ability to work with different backends and queue service providers. Installing and Running Running in production For a detailed configuration guide on installing and running Conductor server in production visit Conductor Server documentation. Running In-Memory Server Follow the steps below to quickly bring up a local Conductor instance backed by an in-memory database with a simple kitchen sink workflow that demonstrate all the capabilities of Conductor. !!!warning: In-Memory server is meant for a quick demonstration purpose and does not store the data on disk. All the data is lost once the server dies. Checkout the source from github git clone git@github.com:Netflix/conductor.git Start Local Server cd server ../gradlew server # wait for the server to come online Swagger APIs can be accessed at http://localhost:8080/ Start UI Server cd ui gulp watch Or Start all the services using docker-compose cd docker docker-compose up If you ran it locally, launch UI at http://localhost:3000/ OR if you ran it using docker-compose launch the UI at http://localhost:5000/ !!!Note: The server will load a sample kitchensink workflow definition by default. See here for details. Runtime Model Conductor follows RPC based communication model where workers are running on a separate machine from the server. Workers communicate with server over HTTP based endpoints and employs polling model for managing work queues. Notes Workers are remote systems and communicates over HTTP with the conductor servers. Task Queues are used to schedule tasks for workers. We use dyno-queues internally but it can easily be swapped with SQS or similar pub-sub mechanism. conductor-redis-persistence module uses Dynomite for storing the state and metadata along with Elasticsearch for indexing backend. See section under extending backend for implementing support for different databases for storage and indexing. High Level Steps Steps required for a new workflow to be registered and get executed: Define task definitions used by the workflow. Create the workflow definition Create task worker(s) that polls for scheduled tasks at regular interval Trigger Workflow Execution POST /workflow/{name} { ... //json payload as workflow input } Polling for a task GET /tasks/poll/batch/{taskType} Update task status POST /tasks { outputData : { encodeResult : success , location : http://cdn.example.com/file/location.png //any task specific output }, status : COMPLETED }","title":"Architecture"},{"location":"architecture/#high-level-architecture","text":"The API and storage layers are pluggable and provide ability to work with different backends and queue service providers.","title":"High Level Architecture"},{"location":"architecture/#installing-and-running","text":"Running in production For a detailed configuration guide on installing and running Conductor server in production visit Conductor Server documentation.","title":"Installing and Running"},{"location":"architecture/#running-in-memory-server","text":"Follow the steps below to quickly bring up a local Conductor instance backed by an in-memory database with a simple kitchen sink workflow that demonstrate all the capabilities of Conductor. !!!warning: In-Memory server is meant for a quick demonstration purpose and does not store the data on disk. All the data is lost once the server dies.","title":"Running In-Memory Server"},{"location":"architecture/#checkout-the-source-from-github","text":"git clone git@github.com:Netflix/conductor.git","title":"Checkout the source from github"},{"location":"architecture/#start-local-server","text":"cd server ../gradlew server # wait for the server to come online Swagger APIs can be accessed at http://localhost:8080/","title":"Start Local Server"},{"location":"architecture/#start-ui-server","text":"cd ui gulp watch","title":"Start UI Server"},{"location":"architecture/#or-start-all-the-services-using-docker-compose","text":"cd docker docker-compose up If you ran it locally, launch UI at http://localhost:3000/ OR if you ran it using docker-compose launch the UI at http://localhost:5000/ !!!Note: The server will load a sample kitchensink workflow definition by default. See here for details.","title":"Or Start all the services using docker-compose"},{"location":"architecture/#runtime-model","text":"Conductor follows RPC based communication model where workers are running on a separate machine from the server. Workers communicate with server over HTTP based endpoints and employs polling model for managing work queues. Notes Workers are remote systems and communicates over HTTP with the conductor servers. Task Queues are used to schedule tasks for workers. We use dyno-queues internally but it can easily be swapped with SQS or similar pub-sub mechanism. conductor-redis-persistence module uses Dynomite for storing the state and metadata along with Elasticsearch for indexing backend. See section under extending backend for implementing support for different databases for storage and indexing.","title":"Runtime Model"},{"location":"architecture/#high-level-steps","text":"Steps required for a new workflow to be registered and get executed: Define task definitions used by the workflow. Create the workflow definition Create task worker(s) that polls for scheduled tasks at regular interval Trigger Workflow Execution POST /workflow/{name} { ... //json payload as workflow input } Polling for a task GET /tasks/poll/batch/{taskType} Update task status POST /tasks { outputData : { encodeResult : success , location : http://cdn.example.com/file/location.png //any task specific output }, status : COMPLETED }","title":"High Level Steps"},{"location":"bestpractices/","text":"Response Timeout Configure the responseTimeoutSeconds of each task to be 0. This value should at least be equal to or greater than the value of timeoutSeconds. Payload sizes Configure your workflows such that conductor is not used as a persistence store. Ensure that the output data in the task result set in your worker is used by your workflow for execution. If the values in the output payloads are not used by subsequent tasks in your workflow, this data should not be sent back to conductor in the task result. In cases where the output data of your task is used within subsequent tasks in your workflow but is substantially large ( 100KB), consider uploading this data to an object store (S3 or similar) and set the location to the object in your task output. The subsequent tasks can then download this data from the given location and use it during execution.","title":"Best Practices"},{"location":"bestpractices/#response-timeout","text":"Configure the responseTimeoutSeconds of each task to be 0. This value should at least be equal to or greater than the value of timeoutSeconds.","title":"Response Timeout"},{"location":"bestpractices/#payload-sizes","text":"Configure your workflows such that conductor is not used as a persistence store. Ensure that the output data in the task result set in your worker is used by your workflow for execution. If the values in the output payloads are not used by subsequent tasks in your workflow, this data should not be sent back to conductor in the task result. In cases where the output data of your task is used within subsequent tasks in your workflow but is substantially large ( 100KB), consider uploading this data to an object store (S3 or similar) and set the location to the object in your task output. The subsequent tasks can then download this data from the given location and use it during execution.","title":"Payload sizes"},{"location":"extend/","text":"Backend Conductor provides a pluggable backend. The current implementation uses Dynomite. There are 4 interfaces that needs to be implemented for each backend: //Store for workflow and task definitions com . netflix . conductor . dao . MetadataDAO //Store for workflow executions com . netflix . conductor . dao . ExecutionDAO //Index for workflow executions com . netflix . conductor . dao . IndexDAO //Queue provider for tasks com . netflix . conductor . dao . QueueDAO It is possible to mix and match different implementations for each of these. For example, SQS for queueing and a relational store for others. System Tasks To create system tasks follow the steps below: Extend com.netflix.conductor.core.execution.tasks.WorkflowSystemTask Instantiate the new class as part of the startup (eager singleton) Implement the TaskMapper interface Add this implementation to the map identified by TaskMappers External Payload Storage To configure conductor to externalize the storage of large payloads: Implement the ExternalPayloadStorage interface . Add the storage option to the enum here . Set this JVM system property workflow.external.payload.storage to the value of the enum element added above. Add a binding similar to this . Workflow Status Listener To provide a notification mechanism upon completion/termination of workflows: Implement the WorkflowStatusListener interface This can be configured to plugin custom notification/eventing upon workflows reaching a terminal state.","title":"Extending Conductor"},{"location":"extend/#backend","text":"Conductor provides a pluggable backend. The current implementation uses Dynomite. There are 4 interfaces that needs to be implemented for each backend: //Store for workflow and task definitions com . netflix . conductor . dao . MetadataDAO //Store for workflow executions com . netflix . conductor . dao . ExecutionDAO //Index for workflow executions com . netflix . conductor . dao . IndexDAO //Queue provider for tasks com . netflix . conductor . dao . QueueDAO It is possible to mix and match different implementations for each of these. For example, SQS for queueing and a relational store for others.","title":"Backend"},{"location":"extend/#system-tasks","text":"To create system tasks follow the steps below: Extend com.netflix.conductor.core.execution.tasks.WorkflowSystemTask Instantiate the new class as part of the startup (eager singleton) Implement the TaskMapper interface Add this implementation to the map identified by TaskMappers","title":"System Tasks"},{"location":"extend/#external-payload-storage","text":"To configure conductor to externalize the storage of large payloads: Implement the ExternalPayloadStorage interface . Add the storage option to the enum here . Set this JVM system property workflow.external.payload.storage to the value of the enum element added above. Add a binding similar to this .","title":"External Payload Storage"},{"location":"extend/#workflow-status-listener","text":"To provide a notification mechanism upon completion/termination of workflows: Implement the WorkflowStatusListener interface This can be configured to plugin custom notification/eventing upon workflows reaching a terminal state.","title":"Workflow Status Listener"},{"location":"externalpayloadstorage/","text":"Warning The external payload storage is currently only implemented to be used to by the Java client. Client libraries in other languages need to be modified to enable this. Contributions are welcomed. Context Conductor can be configured to enforce barriers on the size of workflow and task payloads for both input and output. These barriers can be used as safeguards to prevent the usage of conductor as a data persistence system and to reduce the pressure on its datastore. Barriers Conductor typically applies two kinds of barriers: Soft Barrier Hard Barrier Soft Barrier The soft barrier is used to alleviate pressure on the conductor datastore. In some special workflow use-cases, the size of the payload is warranted enough to be stored as part of the workflow execution. In such cases, conductor externalizes the storage of such payloads to S3 and uploads/downloads to/from S3 as needed during the execution. This process is completely transparent to the user/worker process. Hard Barrier The hard barriers are enforced to safeguard the conductor backend from the pressure of having to persist and deal with voluminous data which is not essential for workflow execution. In such cases, conductor will reject such payloads and will terminate/fail the workflow execution with the reasonForIncompletion set to an appropriate error message detailing the payload size. Usage Conductor provides an implementation of Amazon S3 used to externalize large payload storage. Set the following property in the JVM system properties: workflow.external.payload.storage=S3 Note This implementation assumes that S3 access is configured on the instance. Set the following properties to the desired values in the JVM system properties: Property Description default value workflow.external.payload.storage.s3.bucket S3 bucket where the payloads will be stored workflow.external.payload.storage.s3.signedurlexpirationseconds The expiration time in seconds of the signed url for the payload 5 conductor.workflow.input.payload.threshold.kb Soft barrier for workflow input payload in KB 5120 conductor.max.workflow.input.payload.threshold.kb Hard barrier for workflow input payload in KB 10240 conductor.workflow.output.payload.threshold.kb Soft barrier for workflow output payload in KB 5120 conductor.max.workflow.output.payload.threshold.kb Hard barrier for workflow output payload in KB 10240 conductor.task.input.payload.threshold.kb Soft barrier for task input payload in KB 3072 conductor.max.task.input.payload.threshold.kb Hard barrier for task input payload in KB 10240 conductor.task.output.payload.threshold.kb Soft barrier for task output payload in KB 3072 conductor.max.task.output.payload.threshold.kb Hard barrier for task output payload in KB 10240 The payloads will be stored in the bucket configured above in a UUID.json file at locations determined by the type of the payload. See here for information about how the object key is determined.","title":"External Payload Storage"},{"location":"externalpayloadstorage/#context","text":"Conductor can be configured to enforce barriers on the size of workflow and task payloads for both input and output. These barriers can be used as safeguards to prevent the usage of conductor as a data persistence system and to reduce the pressure on its datastore.","title":"Context"},{"location":"externalpayloadstorage/#barriers","text":"Conductor typically applies two kinds of barriers: Soft Barrier Hard Barrier","title":"Barriers"},{"location":"externalpayloadstorage/#soft-barrier","text":"The soft barrier is used to alleviate pressure on the conductor datastore. In some special workflow use-cases, the size of the payload is warranted enough to be stored as part of the workflow execution. In such cases, conductor externalizes the storage of such payloads to S3 and uploads/downloads to/from S3 as needed during the execution. This process is completely transparent to the user/worker process.","title":"Soft Barrier"},{"location":"externalpayloadstorage/#hard-barrier","text":"The hard barriers are enforced to safeguard the conductor backend from the pressure of having to persist and deal with voluminous data which is not essential for workflow execution. In such cases, conductor will reject such payloads and will terminate/fail the workflow execution with the reasonForIncompletion set to an appropriate error message detailing the payload size.","title":"Hard Barrier"},{"location":"externalpayloadstorage/#usage","text":"Conductor provides an implementation of Amazon S3 used to externalize large payload storage. Set the following property in the JVM system properties: workflow.external.payload.storage=S3 Note This implementation assumes that S3 access is configured on the instance. Set the following properties to the desired values in the JVM system properties: Property Description default value workflow.external.payload.storage.s3.bucket S3 bucket where the payloads will be stored workflow.external.payload.storage.s3.signedurlexpirationseconds The expiration time in seconds of the signed url for the payload 5 conductor.workflow.input.payload.threshold.kb Soft barrier for workflow input payload in KB 5120 conductor.max.workflow.input.payload.threshold.kb Hard barrier for workflow input payload in KB 10240 conductor.workflow.output.payload.threshold.kb Soft barrier for workflow output payload in KB 5120 conductor.max.workflow.output.payload.threshold.kb Hard barrier for workflow output payload in KB 10240 conductor.task.input.payload.threshold.kb Soft barrier for task input payload in KB 3072 conductor.max.task.input.payload.threshold.kb Hard barrier for task input payload in KB 10240 conductor.task.output.payload.threshold.kb Soft barrier for task output payload in KB 3072 conductor.max.task.output.payload.threshold.kb Hard barrier for task output payload in KB 10240 The payloads will be stored in the bucket configured above in a UUID.json file at locations determined by the type of the payload. See here for information about how the object key is determined.","title":"Usage"},{"location":"faq/","text":"How do you schedule a task to be put in the queue after some time (e.g. 1 hour, 1 day etc.) After polling for the task update the status of the task to IN_PROGRESS and set the callbackAfterSeconds value to the desired time. The task will remain in the queue until the specified second before worker polling for it will receive it again. If there is a timeout set for the task, and the callbackAfterSeconds exceeds the timeout value, it will result in task being TIMED_OUT. How long can a workflow be in running state? Can I have a workflow that keeps running for days or months? Yes. As long as the timeouts on the tasks are set to handle long running workflows, it will stay in running state. My workflow fails to start with missing task error Ensure all the tasks are registered via /metadata/taskdefs APIs. Add any missing task definition (as reported in the error) and try again. Where does my worker run? How does conductor run my tasks? Conductor does not run the workers. When a task is scheduled, it is put into the queue maintained by Conductor. Workers are required to poll for tasks using /tasks/poll API at periodic interval, execute the business logic for the task and report back the results using POST /tasks API call. Conductor, however will run system tasks on the Conductor server. How can I schedule workflows to run at a specific time? Conductor does not provide any scheduling mechanism. But you can use any of the available scheduling systems to make REST calls to Conductor to start a workflow. Alternatively, publish a message to a supported eventing system like SQS to trigger a workflow. More details about eventing . How do I setup Dynomite cluster? Visit Dynomite's github page. https://github.com/Netflix/dynomite to find details on setup and support mechanism. Can I use conductor with Ruby / Go / Python? Yes. Workers can be written any language as long as they can poll and update the task results via HTTP endpoints. Conductor provides frameworks for Java and Python to simplify the task of polling and updating the status back to Conductor server. Note: Python and Go clients have been contributed by the community. How can I get help with Dynomite? Visit Dynomite's github page. https://github.com/Netflix/dynomite to find details on setup and support mechanism. My workflow is running and the task is SCHEDULED but it is not being processed. Make sure that the worker is actively polling for this task. Navigate to the Poll Data tab on the Condictor UI and search for your task name in the search box on the top right corner. Ensure that Last Poll Time for this task is current and the Last Polled By is an active instance. The Size column shows the number of scheduled tasks for this task name. How do I configure a notification when my workflow completes or fails? Refer this documentation to extend conductor to send out events/notifications upon workflow completion/failure.","title":"FAQ"},{"location":"faq/#how-do-you-schedule-a-task-to-be-put-in-the-queue-after-some-time-eg-1-hour-1-day-etc","text":"After polling for the task update the status of the task to IN_PROGRESS and set the callbackAfterSeconds value to the desired time. The task will remain in the queue until the specified second before worker polling for it will receive it again. If there is a timeout set for the task, and the callbackAfterSeconds exceeds the timeout value, it will result in task being TIMED_OUT.","title":"How do you schedule a task to be put in the queue after some time (e.g. 1 hour, 1 day etc.)"},{"location":"faq/#how-long-can-a-workflow-be-in-running-state-can-i-have-a-workflow-that-keeps-running-for-days-or-months","text":"Yes. As long as the timeouts on the tasks are set to handle long running workflows, it will stay in running state.","title":"How long can a workflow be in running state?  Can I have a workflow that keeps running for days or months?"},{"location":"faq/#my-workflow-fails-to-start-with-missing-task-error","text":"Ensure all the tasks are registered via /metadata/taskdefs APIs. Add any missing task definition (as reported in the error) and try again.","title":"My workflow fails to start with missing task error"},{"location":"faq/#where-does-my-worker-run-how-does-conductor-run-my-tasks","text":"Conductor does not run the workers. When a task is scheduled, it is put into the queue maintained by Conductor. Workers are required to poll for tasks using /tasks/poll API at periodic interval, execute the business logic for the task and report back the results using POST /tasks API call. Conductor, however will run system tasks on the Conductor server.","title":"Where does my worker run?  How does conductor run my tasks?"},{"location":"faq/#how-can-i-schedule-workflows-to-run-at-a-specific-time","text":"Conductor does not provide any scheduling mechanism. But you can use any of the available scheduling systems to make REST calls to Conductor to start a workflow. Alternatively, publish a message to a supported eventing system like SQS to trigger a workflow. More details about eventing .","title":"How can I schedule workflows to run at a specific time?"},{"location":"faq/#how-do-i-setup-dynomite-cluster","text":"Visit Dynomite's github page. https://github.com/Netflix/dynomite to find details on setup and support mechanism.","title":"How do I setup Dynomite cluster?"},{"location":"faq/#can-i-use-conductor-with-ruby-go-python","text":"Yes. Workers can be written any language as long as they can poll and update the task results via HTTP endpoints. Conductor provides frameworks for Java and Python to simplify the task of polling and updating the status back to Conductor server. Note: Python and Go clients have been contributed by the community.","title":"Can I use conductor with Ruby / Go / Python?"},{"location":"faq/#how-can-i-get-help-with-dynomite","text":"Visit Dynomite's github page. https://github.com/Netflix/dynomite to find details on setup and support mechanism.","title":"How can I get help with Dynomite?"},{"location":"faq/#my-workflow-is-running-and-the-task-is-scheduled-but-it-is-not-being-processed","text":"Make sure that the worker is actively polling for this task. Navigate to the Poll Data tab on the Condictor UI and search for your task name in the search box on the top right corner. Ensure that Last Poll Time for this task is current and the Last Polled By is an active instance. The Size column shows the number of scheduled tasks for this task name.","title":"My workflow is running and the task is SCHEDULED but it is not being processed."},{"location":"faq/#how-do-i-configure-a-notification-when-my-workflow-completes-or-fails","text":"Refer this documentation to extend conductor to send out events/notifications upon workflow completion/failure.","title":"How do I configure a notification when my workflow completes or fails?"},{"location":"license/","text":"Copyright 2018 Netflix, Inc. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.","title":"License"},{"location":"server/","text":"Installing Requirements Database : Dynomite Indexing Backend : Elasticsearch 5.x Servlet Container : Tomcat, Jetty, or similar running JDK 1.8 or higher There are 3 ways in which you can install Conductor: 1. Build from source To build from source, checkout the code from github and build server module using gradle build command. If you do not have gradle installed, you can run the command ./gradlew build from the project root. This produces conductor-server-all-VERSION.jar in the folder ./server/build/libs/ The jar can be executed using: java -jar conductor-server-VERSION-all.jar 2. Download pre-built binaries from jcenter or maven central Use the following coordinates: group artifact version com.netflix.conductor conductor-server-all 2.7.+ 3. Use the pre-configured Docker image To build the docker images for the conductor server and ui run the commands: cd docker docker-compose build After the docker images are built, run the following command to start the containers: docker-compose up This will create a docker container network that consists of the following images: conductor:server, conductor:ui, elasticsearch:5.6.8 , and dynomite. To view the UI, navigate to localhost:5000 , to view the Swagger docs, navigate to localhost:8080 . Configuration Conductor server uses a property file based configuration. The property file is passed to the Main class as a command line argument. java -jar conductor-server-all-VERSION.jar [ PATH TO PROPERTY FILE ] [ log4j.properties file path ] log4j.properties file path is optional and allows finer control over the logging (defaults to INFO level logging in the console). Configuration Parameters # Database persistence model. Possible values are memory, redis, redis_cluster, redis_sentinel and dynomite. # If omitted, the persistence used is memory # # memory : The data is stored in memory and lost when the server dies. Useful for testing or demo # redis : non-Dynomite based redis instance # redis_cluster: AWS Elasticache Redis (cluster mode enabled).See [http://docs.aws.amazon.com/AmazonElastiCache/latest/UserGuide/Clusters.Create.CON.RedisCluster.html] # redis_sentinel: Redis HA with Redis Sentinel. See [https://redis.io/topics/sentinel] # dynomite : Dynomite cluster. Use this for HA configuration. db = dynomite # Dynomite Cluster details. # format is host:port:rack separated by semicolon # for AWS Elasticache Redis (cluster mode enabled) the format is configuration_endpoint:port:us-east-1e. The region in this case does not matter workflow.dynomite.cluster.hosts = host1:8102:us-east-1c;host2:8102:us-east-1d;host3:8102:us-east-1e # If you are running using dynomite, also add the following line to the property # to set the rack/availability zone of the conductor server to be same as dynomite cluster config EC2_AVAILABILTY_ZONE = us-east-1c # Dynomite cluster name workflow.dynomite.cluster.name = dyno_cluster_name # Maximum connections to redis/dynomite workflow.dynomite.connection.maxConnsPerHost = 31 # Namespace for the keys stored in Dynomite/Redis workflow.namespace.prefix = conductor # Namespace prefix for the dyno queues workflow.namespace.queue.prefix = conductor_queues # No. of threads allocated to dyno-queues (optional) queues.dynomite.threads = 10 # Non-quorum port used to connect to local redis. Used by dyno-queues. # When using redis directly, set this to the same port as redis server. # For Dynomite, this is 22122 by default or the local redis-server port used by Dynomite. queues.dynomite.nonQuorum.port = 22122 # Transport address to elasticsearch # Specifying multiple node urls is not supported. specify one of the nodes url, or a load balancer. workflow.elasticsearch.url = localhost:9300 # Name of the elasticsearch cluster workflow.elasticsearch.index.name = conductor # Additional modules (optional) conductor.additional.modules = class_extending_com.google.inject.AbstractModule High Availability Configuration Conductor servers are stateless and can be deployed on multiple servers to handle scale and availability needs. The scalability of the server is achieved by scaling the Dynomite cluster along with dyno-queues which is used for queues. Clients connects to the server via HTTP load balancer or using Discovery (on NetflixOSS stack). Using Standalone Redis / ElastiCache Conductor server can be used with a standlone Redis or ElastiCache server. To configure the server, change the config to use the following: db = redis # For AWS Elasticache Redis (cluster mode enabled) the format is configuration_endpoint:port:us-east-1e. # The region in this case does not matter workflow.dynomite.cluster.hosts = server_address:server_port:us-east-1e workflow.dynomite.connection.maxConnsPerHost = 31 queues.dynomite.nonQuorum.port = server_port","title":"Conductor Server"},{"location":"server/#installing","text":"","title":"Installing"},{"location":"server/#requirements","text":"Database : Dynomite Indexing Backend : Elasticsearch 5.x Servlet Container : Tomcat, Jetty, or similar running JDK 1.8 or higher There are 3 ways in which you can install Conductor:","title":"Requirements"},{"location":"server/#1-build-from-source","text":"To build from source, checkout the code from github and build server module using gradle build command. If you do not have gradle installed, you can run the command ./gradlew build from the project root. This produces conductor-server-all-VERSION.jar in the folder ./server/build/libs/ The jar can be executed using: java -jar conductor-server-VERSION-all.jar","title":"1. Build from source"},{"location":"server/#2-download-pre-built-binaries-from-jcenter-or-maven-central","text":"Use the following coordinates: group artifact version com.netflix.conductor conductor-server-all 2.7.+","title":"2. Download pre-built binaries from jcenter or maven central"},{"location":"server/#3-use-the-pre-configured-docker-image","text":"To build the docker images for the conductor server and ui run the commands: cd docker docker-compose build After the docker images are built, run the following command to start the containers: docker-compose up This will create a docker container network that consists of the following images: conductor:server, conductor:ui, elasticsearch:5.6.8 , and dynomite. To view the UI, navigate to localhost:5000 , to view the Swagger docs, navigate to localhost:8080 .","title":"3. Use the pre-configured Docker image"},{"location":"server/#configuration","text":"Conductor server uses a property file based configuration. The property file is passed to the Main class as a command line argument. java -jar conductor-server-all-VERSION.jar [ PATH TO PROPERTY FILE ] [ log4j.properties file path ] log4j.properties file path is optional and allows finer control over the logging (defaults to INFO level logging in the console).","title":"Configuration"},{"location":"server/#configuration-parameters","text":"# Database persistence model. Possible values are memory, redis, redis_cluster, redis_sentinel and dynomite. # If omitted, the persistence used is memory # # memory : The data is stored in memory and lost when the server dies. Useful for testing or demo # redis : non-Dynomite based redis instance # redis_cluster: AWS Elasticache Redis (cluster mode enabled).See [http://docs.aws.amazon.com/AmazonElastiCache/latest/UserGuide/Clusters.Create.CON.RedisCluster.html] # redis_sentinel: Redis HA with Redis Sentinel. See [https://redis.io/topics/sentinel] # dynomite : Dynomite cluster. Use this for HA configuration. db = dynomite # Dynomite Cluster details. # format is host:port:rack separated by semicolon # for AWS Elasticache Redis (cluster mode enabled) the format is configuration_endpoint:port:us-east-1e. The region in this case does not matter workflow.dynomite.cluster.hosts = host1:8102:us-east-1c;host2:8102:us-east-1d;host3:8102:us-east-1e # If you are running using dynomite, also add the following line to the property # to set the rack/availability zone of the conductor server to be same as dynomite cluster config EC2_AVAILABILTY_ZONE = us-east-1c # Dynomite cluster name workflow.dynomite.cluster.name = dyno_cluster_name # Maximum connections to redis/dynomite workflow.dynomite.connection.maxConnsPerHost = 31 # Namespace for the keys stored in Dynomite/Redis workflow.namespace.prefix = conductor # Namespace prefix for the dyno queues workflow.namespace.queue.prefix = conductor_queues # No. of threads allocated to dyno-queues (optional) queues.dynomite.threads = 10 # Non-quorum port used to connect to local redis. Used by dyno-queues. # When using redis directly, set this to the same port as redis server. # For Dynomite, this is 22122 by default or the local redis-server port used by Dynomite. queues.dynomite.nonQuorum.port = 22122 # Transport address to elasticsearch # Specifying multiple node urls is not supported. specify one of the nodes url, or a load balancer. workflow.elasticsearch.url = localhost:9300 # Name of the elasticsearch cluster workflow.elasticsearch.index.name = conductor # Additional modules (optional) conductor.additional.modules = class_extending_com.google.inject.AbstractModule","title":"Configuration Parameters"},{"location":"server/#high-availability-configuration","text":"Conductor servers are stateless and can be deployed on multiple servers to handle scale and availability needs. The scalability of the server is achieved by scaling the Dynomite cluster along with dyno-queues which is used for queues. Clients connects to the server via HTTP load balancer or using Discovery (on NetflixOSS stack).","title":"High Availability Configuration"},{"location":"server/#using-standalone-redis-elasticache","text":"Conductor server can be used with a standlone Redis or ElastiCache server. To configure the server, change the config to use the following: db = redis # For AWS Elasticache Redis (cluster mode enabled) the format is configuration_endpoint:port:us-east-1e. # The region in this case does not matter workflow.dynomite.cluster.hosts = server_address:server_port:us-east-1e workflow.dynomite.connection.maxConnsPerHost = 31 queues.dynomite.nonQuorum.port = server_port","title":"Using Standalone Redis / ElastiCache"},{"location":"tasklifecycle/","text":"Task state transitions The figure below depicts the state transitions that a task can go through within a workflow execution. Retries and Failure Scenarios Task failure and retries Retries for failed task executions of each task can be configured independently. retryCount, retryDelaySeconds and retryLogic can be used to configure the retry mechanism. Worker (W1) polls for task T1 from the Conductor server and receives the task. Upon processing this task, the worker determines that the task execution is a failure and reports this to the server with FAILED status after 10 seconds. The server will persist this FAILED execution of T1. A new execution of task T1 will be created and scheduled to be polled. This task will be available to be polled after 5 (retryDelaySeconds) seconds. Timeout seconds Timeout is the maximum amount of time that the task must reach a terminal state in, else the task will be marked as TIMED_OUT. 0 seconds - Worker polls for task T1 fom the Conductor server and receives the task. T1 is put into IN_PROGRESS status by the server. Worker starts processing the task but is unable to process the task at this time. Worker updates the server with T1 set to IN_PROGRESS status and a callback of 9 seconds. Server puts T1 back in the queue but makes it invisible and the worker continues to poll for the task but does not receive T1 for 9 seconds. 9,18 seconds - Worker receives T1 from the server and is still unable to process the task and updates the server with a callback of 9 seconds. 27 seconds - Worker polls and receives task T1 from the server and is now able to process this task. 30 seconds (T1 timeout) - Server marks T1 as TIMED_OUT because it is not in a terminal state after first being moved to IN_PROGRESS status. Server schedules a new task based on the retry count. 32 seconds - Worker completes processing of T1 and updates the server with COMPLETED status. Server will ignore this update since T1 has already been moved to a terminal status (TIMED_OUT). Response timeout seconds Response timeout is the time within which the worker must respond to the server with an update for the task, else the task will be marked as TIMED_OUT. 0 seconds - Worker polls for the task T1 from the Conductor server and receives the task. T1 is put into IN_PROGRESS status by the server. Worker starts processing the task but the worker instance dies during this execution. 20 seconds (T1 responseTimeout) - Server marks T1 as TIMED_OUT since the task has not been updated by the worker within the configured responseTimeoutSeconds (20). A new instance of task T1 is scheduled as per the retry configuration. 25 seconds - The retried instance of T1 is available to be polled by the worker, after the retryDelaySeconds (5) has elapsed.","title":"Task Lifecycle"},{"location":"tasklifecycle/#task-state-transitions","text":"The figure below depicts the state transitions that a task can go through within a workflow execution.","title":"Task state transitions"},{"location":"tasklifecycle/#retries-and-failure-scenarios","text":"","title":"Retries and Failure Scenarios"},{"location":"tasklifecycle/#task-failure-and-retries","text":"Retries for failed task executions of each task can be configured independently. retryCount, retryDelaySeconds and retryLogic can be used to configure the retry mechanism. Worker (W1) polls for task T1 from the Conductor server and receives the task. Upon processing this task, the worker determines that the task execution is a failure and reports this to the server with FAILED status after 10 seconds. The server will persist this FAILED execution of T1. A new execution of task T1 will be created and scheduled to be polled. This task will be available to be polled after 5 (retryDelaySeconds) seconds.","title":"Task failure and retries"},{"location":"tasklifecycle/#timeout-seconds","text":"Timeout is the maximum amount of time that the task must reach a terminal state in, else the task will be marked as TIMED_OUT. 0 seconds - Worker polls for task T1 fom the Conductor server and receives the task. T1 is put into IN_PROGRESS status by the server. Worker starts processing the task but is unable to process the task at this time. Worker updates the server with T1 set to IN_PROGRESS status and a callback of 9 seconds. Server puts T1 back in the queue but makes it invisible and the worker continues to poll for the task but does not receive T1 for 9 seconds. 9,18 seconds - Worker receives T1 from the server and is still unable to process the task and updates the server with a callback of 9 seconds. 27 seconds - Worker polls and receives task T1 from the server and is now able to process this task. 30 seconds (T1 timeout) - Server marks T1 as TIMED_OUT because it is not in a terminal state after first being moved to IN_PROGRESS status. Server schedules a new task based on the retry count. 32 seconds - Worker completes processing of T1 and updates the server with COMPLETED status. Server will ignore this update since T1 has already been moved to a terminal status (TIMED_OUT).","title":"Timeout seconds"},{"location":"tasklifecycle/#response-timeout-seconds","text":"Response timeout is the time within which the worker must respond to the server with an update for the task, else the task will be marked as TIMED_OUT. 0 seconds - Worker polls for the task T1 from the Conductor server and receives the task. T1 is put into IN_PROGRESS status by the server. Worker starts processing the task but the worker instance dies during this execution. 20 seconds (T1 responseTimeout) - Server marks T1 as TIMED_OUT since the task has not been updated by the worker within the configured responseTimeoutSeconds (20). A new instance of task T1 is scheduled as per the retry configuration. 25 seconds - The retried instance of T1 is available to be polled by the worker, after the retryDelaySeconds (5) has elapsed.","title":"Response timeout seconds"},{"location":"configuration/eventhandlers/","text":"Introduction Eventing in Conductor provides for loose coupling between workflows and support for producing and consuming events from external systems. This includes: Being able to produce an event (message) in an external system like SQS or internal to Conductor. Start a workflow when a specific event occurs that matches the provided criteria. Conductor provides SUB_WORKFLOW task that can be used to embed a workflow inside parent workflow. Eventing supports provides similar capability without explicitly adding dependencies and provides fire-and-forget style integrations. Event Task Event task provides ability to publish an event (message) to either Conductor or an external eventing system like SQS. Event tasks are useful for creating event based dependencies for workflows and tasks. See Event Task for documentation. Event Handler Event handlers are listeners registered that executes an action when a matching event occurs. The supported actions are: Start a Workflow Fail a Task Complete a Task Event Handlers can be configured to listen to Conductor Events or an external event like SQS. Configuration Event Handlers are configured via /event/ APIs. Structure: { name : descriptive unique name , event : event_type:event_location , condition : boolean condition , actions : [ see examples below ] } Condition Condition is an expression that MUST evaluate to a boolean value. A Javascript like syntax is supported that can be used to evaluate condition based on the payload. Actions are executed only when the condition evaluates to true . Examples Given the following payload in the message: { fileType : AUDIO , version : 3 , metadata : { length : 300 , codec : aac } } Expression Result $.version 1 true $.version 10 false $.metadata.length == 300 true Actions Start A Workflow { action : start_workflow , start_workflow : { name : WORKFLOW_NAME , version : optional_param , input : { param1 : ${param1} } } } Complete Task * { action : complete_task , complete_task : { workflowId : ${workflowId} , taskRefName : task_1 , output : { response : ${result} } }, expandInlineJSON : true } Fail Task * { action : fail_task , fail_task : { workflowId : ${workflowId} , taskRefName : task_1 , output : { response : ${result} } }, expandInlineJSON : true } Input for starting a workflow and output when completing / failing task follows the same expressions used for wiring workflow inputs. Expanding stringified JSON elements in payload expandInlineJSON property, when set to true will expand the inlined stringified JSON elements in the payload to JSON documents and replace the string value with JSON document. This feature allows such elements to be used with JSON path expressions. Extending Provide the implementation of EventQueueProvider . SQS Queue Provider: SQSEventQueueProvider.java","title":"Event Handlers"},{"location":"configuration/eventhandlers/#introduction","text":"Eventing in Conductor provides for loose coupling between workflows and support for producing and consuming events from external systems. This includes: Being able to produce an event (message) in an external system like SQS or internal to Conductor. Start a workflow when a specific event occurs that matches the provided criteria. Conductor provides SUB_WORKFLOW task that can be used to embed a workflow inside parent workflow. Eventing supports provides similar capability without explicitly adding dependencies and provides fire-and-forget style integrations.","title":"Introduction"},{"location":"configuration/eventhandlers/#event-task","text":"Event task provides ability to publish an event (message) to either Conductor or an external eventing system like SQS. Event tasks are useful for creating event based dependencies for workflows and tasks. See Event Task for documentation.","title":"Event Task"},{"location":"configuration/eventhandlers/#event-handler","text":"Event handlers are listeners registered that executes an action when a matching event occurs. The supported actions are: Start a Workflow Fail a Task Complete a Task Event Handlers can be configured to listen to Conductor Events or an external event like SQS.","title":"Event Handler"},{"location":"configuration/eventhandlers/#configuration","text":"Event Handlers are configured via /event/ APIs.","title":"Configuration"},{"location":"configuration/eventhandlers/#structure","text":"{ name : descriptive unique name , event : event_type:event_location , condition : boolean condition , actions : [ see examples below ] }","title":"Structure:"},{"location":"configuration/eventhandlers/#condition","text":"Condition is an expression that MUST evaluate to a boolean value. A Javascript like syntax is supported that can be used to evaluate condition based on the payload. Actions are executed only when the condition evaluates to true . Examples Given the following payload in the message: { fileType : AUDIO , version : 3 , metadata : { length : 300 , codec : aac } } Expression Result $.version 1 true $.version 10 false $.metadata.length == 300 true","title":"Condition"},{"location":"configuration/eventhandlers/#actions","text":"Start A Workflow { action : start_workflow , start_workflow : { name : WORKFLOW_NAME , version : optional_param , input : { param1 : ${param1} } } } Complete Task * { action : complete_task , complete_task : { workflowId : ${workflowId} , taskRefName : task_1 , output : { response : ${result} } }, expandInlineJSON : true } Fail Task * { action : fail_task , fail_task : { workflowId : ${workflowId} , taskRefName : task_1 , output : { response : ${result} } }, expandInlineJSON : true } Input for starting a workflow and output when completing / failing task follows the same expressions used for wiring workflow inputs. Expanding stringified JSON elements in payload expandInlineJSON property, when set to true will expand the inlined stringified JSON elements in the payload to JSON documents and replace the string value with JSON document. This feature allows such elements to be used with JSON path expressions.","title":"Actions"},{"location":"configuration/eventhandlers/#extending","text":"Provide the implementation of EventQueueProvider . SQS Queue Provider: SQSEventQueueProvider.java","title":"Extending"},{"location":"configuration/systask/","text":"Decision A decision task is similar to case...switch statement in a programming language. The task takes 3 parameters: Parameters: name description caseValueParam Name of the parameter in task input whose value will be used as a switch. decisionCases Map where key is possible values of caseValueParam with value being list of tasks to be executed. defaultCase List of tasks to be executed when no matching value if found in decision case (default condition) Example { name : decide_task , taskReferenceName : decide1 , inputParameters : { case_value_param : ${workflow.input.movieType} }, type : DECISION , caseValueParam : case_value_param , decisionCases : { Show : [ { name : setup_episodes , taskReferenceName : se1 , inputParameters : { movieId : ${workflow.input.movieId} }, type : SIMPLE }, { name : generate_episode_artwork , taskReferenceName : ga , inputParameters : { movieId : ${workflow.input.movieId} }, type : SIMPLE } ], Movie : [ { name : setup_movie , taskReferenceName : sm , inputParameters : { movieId : ${workflow.input.movieId} }, type : SIMPLE }, { name : generate_movie_artwork , taskReferenceName : gma , inputParameters : { movieId : ${workflow.input.movieId} }, type : SIMPLE } ] } } Event Event task provides ability to publish an event (message) to either Conductor or an external eventing system like SQS. Event tasks are useful for creating event based dependencies for workflows and tasks. Parameters: name description sink Qualified name of the event that is produced. e.g. conductor or sqs:sqs_queue_name Example { sink : sqs:example_sqs_queue_name } When producing an event with Conductor as sink, the event name follows the structure: conductor: workflow_name : task_reference_name For SQS, use the name of the queue and NOT the URI. Conductor looks up the URI based on the name. Warning When using SQS add the ContribsModule to the deployment. The module needs to be configured with AWSCredentialsProvider for Conductor to be able to use AWS APIs. Supported Sinks Conductor SQS Event Task Input The input given to the event task is made available to the published message as payload. e.g. if a message is put into SQS queue (sink is sqs) then the message payload will be the input to the task. Event Task Output event_produced Name of the event produced. HTTP An HTTP task is used to make calls to another microservice over HTTP. Parameters: The task expects an input parameter named http_request as part of the task's input with the following details: name description uri URI for the service. Can be a partial when using vipAddress or includes the server address. method HTTP method. One of the GET, PUT, POST, DELETE, OPTIONS, HEAD accept Accept header as required by server. contentType Content Type - supported types are text/plain, text/html and, application/json headers A map of additional http headers to be sent along with the request. body Request body vipAddress When using discovery based service URLs. HTTP Task Output name description response JSON body containing the response if one is present headers Response Headers statusCode Integer status code Example Task Input payload using vipAddress { http_request : { vipAddress : examplevip-prod , uri : / , method : GET , accept : text/plain } } Task Input using an absolute URL { http_request : { uri : http://example.com/ , method : GET , accept : text/plain } } The task is marked as FAILED if the request cannot be completed or the remote server returns non successful status code. Note HTTP task currently only supports Content-Type as application/json and is able to parse the text as well as JSON response. XML input/output is currently not supported. However, if the response cannot be parsed as JSON or Text, a string representation is stored as a text value. Sub Workflow Sub Workflow task allows for nesting a workflow within another workflow. Parameters: name description subWorkflowParam name and version of the Workflow to be executed as Sub Workflow. Input to this Task will be forwarded to SubWorflow as Workflow input Example { name : sub_workflow_task , taskReferenceName : sub1 , inputParameters : { requestId : ${workflow.input.requestId} , file : ${encode.output.location} }, type : SUB_WORKFLOW , subWorkflowParam : { name : deployment_workflow , version : 1 } } When executed, a deployment_workflow is executed with two input parameters requestId and file . The task is marked as completed upon the completion of the spawned workflow. If the sub-workflow is terminated or fails the task is marked as failure and retried if configured. Fork Fork is used to schedule parallel set of tasks. Parameters: name description forkTasks A list of list of tasks. Each sublist is scheduled to be executed in parallel. However, tasks within the sublists are scheduled in a serial fashion. Example { forkTasks : [ [ { name : task11 , taskReferenceName : t11 }, { name : task12 , taskReferenceName : t12 } ], [ { name : task21 , taskReferenceName : t21 }, { name : task22 , taskReferenceName : t22 } ] ] } When executed, task11 and task21 are scheduled to be executed at the same time. Dynamic Fork A dynamic fork is same as FORK_JOIN task. Except that the list of tasks to be forked is provided at runtime using task's input. Useful when number of tasks to be forked is not fixed and varies based on the input. name description dynamicForkTasksParam Name of the parameter that contains list of workflow task configuration to be executed in parallel dynamicForkTasksInputParamName Name of the parameter whose value should be a map with key as forked task's reference name and value as input the forked task Example { inputParameters : { dynamicTasks : ${taskA.output.dynamicTasksJSON} , dynamicTasksInput : ${taskA.output.dynamicTasksInputJSON} }, type : FORK_JOIN_DYNAMIC , dynamicForkTasksParam : dynamicTasks , dynamicForkTasksInputParamName : dynamicTasksInput } Consider taskA 's output as: { dynamicTasksInputJSON : { forkedTask1 : { width : 100 , height : 100 , params : { recipe : jpg } }, forkedTask2 : { width : 200 , height : 200 , params : { recipe : jpg } } }, dynamicTasksJSON : [ { name : encode_task , taskReferenceName : forkedTask1 , type : SIMPLE }, { name : encode_task , taskReferenceName : forkedTask2 , type : SIMPLE } ] } When executed, the dynamic fork task will schedule two parallel task of type \"encode_task\" with reference names \"forkedTask1\" and \"forkedTask2\" and inputs as specified by _ dynamicTasksInputJSON_ Dynamic Fork and Join A Join task MUST follow FORK_JOIN_DYNAMIC Workflow definition MUST include a Join task definition followed by FORK_JOIN_DYNAMIC task. However, given the dynamic nature of the task, no joinOn parameters are required for this Join. The join will wait for ALL the forked branches to complete before completing. Unlike FORK, which can execute parallel flows with each fork executing a series of tasks in sequence, FORK_JOIN_DYNAMIC is limited to only one task per fork. However, forked task can be a Sub Workflow, allowing for more complex execution flows. Join Join task is used to wait for completion of one or more tasks spawned by fork tasks. Parameters: name description joinOn List of task reference name, for which the JOIN will wait for completion. Example { joinOn : [ taskRef1 , taskRef3 ] } Join Task Output Fork task's output will be a JSON object with key being the task reference name and value as the output of the fork task. Wait A wait task is implemented as a gate that remains in IN_PROGRESS state unless marked as COMPLETED or FAILED by an external trigger. To use a wait task, set the task type as WAIT Parameters: None required. External Triggers for Wait Task Task Resource endpoint can be used to update the status of a task to a terminate state. Contrib module provides SQS integration where an external system can place a message in a pre-configured queue that the server listens on. As the messages arrive, they are marked as COMPLETED or FAILED . SQS Queues SQS queues used by the server to update the task status can be retrieve using the following API: GET /queue When updating the status of the task, the message needs to conform to the following spec: Message has to be a valid JSON string. The message JSON should contain a key named externalId with the value being a JSONified string that contains the following keys: workflowId : Id of the workflow taskRefName : Task reference name that should be updated. Each queue represents a specific task status and tasks are marked accordingly. e.g. message coming to a COMPLETED queue marks the task status as COMPLETED . Tasks' output is updated with the message. Example SQS Payload: { some_key : valuex , externalId : {\\ taskRefName\\ :\\ TASK_REFERENCE_NAME\\ ,\\ workflowId\\ :\\ WORKFLOW_ID\\ } } Dynamic Task Dynamic Task allows to execute one of the registered Tasks dynamically at run-time. It accepts the task name to execute in inputParameters. Parameters: name description dynamicTaskNameParam Name of the parameter from the task input whose value is used to schedule the task. e.g. if the value of the parameter is ABC, the next task scheduled is of type 'ABC'. Example { name : user_task , taskReferenceName : t1 , inputParameters : { files : ${workflow.input.files} , taskToExecute : ${workflow.input.user_supplied_task} }, type : DYNAMIC , dynamicTaskNameParam : taskToExecute } If the workflow is started with input parameter user_supplied_task's value as user_task_2 , Conductor will schedule user_task_2 when scheduling this dynamic task.","title":"System Tasks"},{"location":"configuration/systask/#decision","text":"A decision task is similar to case...switch statement in a programming language. The task takes 3 parameters: Parameters: name description caseValueParam Name of the parameter in task input whose value will be used as a switch. decisionCases Map where key is possible values of caseValueParam with value being list of tasks to be executed. defaultCase List of tasks to be executed when no matching value if found in decision case (default condition) Example { name : decide_task , taskReferenceName : decide1 , inputParameters : { case_value_param : ${workflow.input.movieType} }, type : DECISION , caseValueParam : case_value_param , decisionCases : { Show : [ { name : setup_episodes , taskReferenceName : se1 , inputParameters : { movieId : ${workflow.input.movieId} }, type : SIMPLE }, { name : generate_episode_artwork , taskReferenceName : ga , inputParameters : { movieId : ${workflow.input.movieId} }, type : SIMPLE } ], Movie : [ { name : setup_movie , taskReferenceName : sm , inputParameters : { movieId : ${workflow.input.movieId} }, type : SIMPLE }, { name : generate_movie_artwork , taskReferenceName : gma , inputParameters : { movieId : ${workflow.input.movieId} }, type : SIMPLE } ] } }","title":"Decision"},{"location":"configuration/systask/#event","text":"Event task provides ability to publish an event (message) to either Conductor or an external eventing system like SQS. Event tasks are useful for creating event based dependencies for workflows and tasks. Parameters: name description sink Qualified name of the event that is produced. e.g. conductor or sqs:sqs_queue_name Example { sink : sqs:example_sqs_queue_name } When producing an event with Conductor as sink, the event name follows the structure: conductor: workflow_name : task_reference_name For SQS, use the name of the queue and NOT the URI. Conductor looks up the URI based on the name. Warning When using SQS add the ContribsModule to the deployment. The module needs to be configured with AWSCredentialsProvider for Conductor to be able to use AWS APIs. Supported Sinks Conductor SQS Event Task Input The input given to the event task is made available to the published message as payload. e.g. if a message is put into SQS queue (sink is sqs) then the message payload will be the input to the task. Event Task Output event_produced Name of the event produced.","title":"Event"},{"location":"configuration/systask/#http","text":"An HTTP task is used to make calls to another microservice over HTTP. Parameters: The task expects an input parameter named http_request as part of the task's input with the following details: name description uri URI for the service. Can be a partial when using vipAddress or includes the server address. method HTTP method. One of the GET, PUT, POST, DELETE, OPTIONS, HEAD accept Accept header as required by server. contentType Content Type - supported types are text/plain, text/html and, application/json headers A map of additional http headers to be sent along with the request. body Request body vipAddress When using discovery based service URLs. HTTP Task Output name description response JSON body containing the response if one is present headers Response Headers statusCode Integer status code Example Task Input payload using vipAddress { http_request : { vipAddress : examplevip-prod , uri : / , method : GET , accept : text/plain } } Task Input using an absolute URL { http_request : { uri : http://example.com/ , method : GET , accept : text/plain } } The task is marked as FAILED if the request cannot be completed or the remote server returns non successful status code. Note HTTP task currently only supports Content-Type as application/json and is able to parse the text as well as JSON response. XML input/output is currently not supported. However, if the response cannot be parsed as JSON or Text, a string representation is stored as a text value.","title":"HTTP"},{"location":"configuration/systask/#sub-workflow","text":"Sub Workflow task allows for nesting a workflow within another workflow. Parameters: name description subWorkflowParam name and version of the Workflow to be executed as Sub Workflow. Input to this Task will be forwarded to SubWorflow as Workflow input Example { name : sub_workflow_task , taskReferenceName : sub1 , inputParameters : { requestId : ${workflow.input.requestId} , file : ${encode.output.location} }, type : SUB_WORKFLOW , subWorkflowParam : { name : deployment_workflow , version : 1 } } When executed, a deployment_workflow is executed with two input parameters requestId and file . The task is marked as completed upon the completion of the spawned workflow. If the sub-workflow is terminated or fails the task is marked as failure and retried if configured.","title":"Sub Workflow"},{"location":"configuration/systask/#fork","text":"Fork is used to schedule parallel set of tasks. Parameters: name description forkTasks A list of list of tasks. Each sublist is scheduled to be executed in parallel. However, tasks within the sublists are scheduled in a serial fashion. Example { forkTasks : [ [ { name : task11 , taskReferenceName : t11 }, { name : task12 , taskReferenceName : t12 } ], [ { name : task21 , taskReferenceName : t21 }, { name : task22 , taskReferenceName : t22 } ] ] } When executed, task11 and task21 are scheduled to be executed at the same time.","title":"Fork"},{"location":"configuration/systask/#dynamic-fork","text":"A dynamic fork is same as FORK_JOIN task. Except that the list of tasks to be forked is provided at runtime using task's input. Useful when number of tasks to be forked is not fixed and varies based on the input. name description dynamicForkTasksParam Name of the parameter that contains list of workflow task configuration to be executed in parallel dynamicForkTasksInputParamName Name of the parameter whose value should be a map with key as forked task's reference name and value as input the forked task Example { inputParameters : { dynamicTasks : ${taskA.output.dynamicTasksJSON} , dynamicTasksInput : ${taskA.output.dynamicTasksInputJSON} }, type : FORK_JOIN_DYNAMIC , dynamicForkTasksParam : dynamicTasks , dynamicForkTasksInputParamName : dynamicTasksInput } Consider taskA 's output as: { dynamicTasksInputJSON : { forkedTask1 : { width : 100 , height : 100 , params : { recipe : jpg } }, forkedTask2 : { width : 200 , height : 200 , params : { recipe : jpg } } }, dynamicTasksJSON : [ { name : encode_task , taskReferenceName : forkedTask1 , type : SIMPLE }, { name : encode_task , taskReferenceName : forkedTask2 , type : SIMPLE } ] } When executed, the dynamic fork task will schedule two parallel task of type \"encode_task\" with reference names \"forkedTask1\" and \"forkedTask2\" and inputs as specified by _ dynamicTasksInputJSON_ Dynamic Fork and Join A Join task MUST follow FORK_JOIN_DYNAMIC Workflow definition MUST include a Join task definition followed by FORK_JOIN_DYNAMIC task. However, given the dynamic nature of the task, no joinOn parameters are required for this Join. The join will wait for ALL the forked branches to complete before completing. Unlike FORK, which can execute parallel flows with each fork executing a series of tasks in sequence, FORK_JOIN_DYNAMIC is limited to only one task per fork. However, forked task can be a Sub Workflow, allowing for more complex execution flows.","title":"Dynamic Fork"},{"location":"configuration/systask/#join","text":"Join task is used to wait for completion of one or more tasks spawned by fork tasks. Parameters: name description joinOn List of task reference name, for which the JOIN will wait for completion. Example { joinOn : [ taskRef1 , taskRef3 ] } Join Task Output Fork task's output will be a JSON object with key being the task reference name and value as the output of the fork task.","title":"Join"},{"location":"configuration/systask/#wait","text":"A wait task is implemented as a gate that remains in IN_PROGRESS state unless marked as COMPLETED or FAILED by an external trigger. To use a wait task, set the task type as WAIT Parameters: None required. External Triggers for Wait Task Task Resource endpoint can be used to update the status of a task to a terminate state. Contrib module provides SQS integration where an external system can place a message in a pre-configured queue that the server listens on. As the messages arrive, they are marked as COMPLETED or FAILED . SQS Queues SQS queues used by the server to update the task status can be retrieve using the following API: GET /queue When updating the status of the task, the message needs to conform to the following spec: Message has to be a valid JSON string. The message JSON should contain a key named externalId with the value being a JSONified string that contains the following keys: workflowId : Id of the workflow taskRefName : Task reference name that should be updated. Each queue represents a specific task status and tasks are marked accordingly. e.g. message coming to a COMPLETED queue marks the task status as COMPLETED . Tasks' output is updated with the message. Example SQS Payload: { some_key : valuex , externalId : {\\ taskRefName\\ :\\ TASK_REFERENCE_NAME\\ ,\\ workflowId\\ :\\ WORKFLOW_ID\\ } }","title":"Wait"},{"location":"configuration/systask/#dynamic-task","text":"Dynamic Task allows to execute one of the registered Tasks dynamically at run-time. It accepts the task name to execute in inputParameters. Parameters: name description dynamicTaskNameParam Name of the parameter from the task input whose value is used to schedule the task. e.g. if the value of the parameter is ABC, the next task scheduled is of type 'ABC'. Example { name : user_task , taskReferenceName : t1 , inputParameters : { files : ${workflow.input.files} , taskToExecute : ${workflow.input.user_supplied_task} }, type : DYNAMIC , dynamicTaskNameParam : taskToExecute } If the workflow is started with input parameter user_supplied_task's value as user_task_2 , Conductor will schedule user_task_2 when scheduling this dynamic task.","title":"Dynamic Task"},{"location":"configuration/taskdef/","text":"Task Definition Conductor maintains a registry of worker tasks. A task MUST be registered before being used in a workflow. Example { name : encode_task , retryCount : 3 , timeoutSeconds : 1200 , inputKeys : [ sourceRequestId , qcElementType ], outputKeys : [ state , skipped , result ], timeoutPolicy : TIME_OUT_WF , retryLogic : FIXED , retryDelaySeconds : 600 , responseTimeoutSeconds : 3600 , concurrentExecLimit : 100 , rateLimitFrequencyInSeconds : 60 , rateLimitPerFrequency : 50 } field description Notes name Task Type. Unique name of the Task that resonates with it's function. Unique description Description of the task optional retryCount No. of retries to attempt when a Task is marked as failure defaults to 3 retryLogic Mechanism for the retries see possible values below retryDelaySeconds Time to wait before retries defaults to 60 seconds timeoutPolicy Task's timeout policy see possible values below timeoutSeconds Time in milliseconds, after which the task is marked as TIMED_OUT if not completed after transitioning to IN_PROGRESS status for the first time No timeouts if set to 0 responseTimeoutSeconds If greater than 0, the task is rescheduled if not updated with a status after this time (heartbeat mechanism). Useful when the worker polls for the task but fails to complete due to errors/network failure. defaults to 0 inputKeys Array of keys of task's expected input. Used for documenting task's input. See Using inputKeys and outputKeys . optional outputKeys Array of keys of task's expected output. Used for documenting task's output optional inputTemplate See Using inputTemplate below. optional concurrentExecLimit Number of tasks that can be executed at any given time. optional rateLimitFrequencyInSeconds, rateLimitPerFrequency See Task Rate limits below. optional Retry Logic FIXED : Reschedule the task after the retryDelaySeconds EXPONENTIAL_BACKOFF : reschedule after retryDelaySeconds * attemptNumber Timeout Policy RETRY : Retries the task again TIME_OUT_WF : Workflow is marked as TIMED_OUT and terminated ALERT_ONLY : Registers a counter (task_timeout) Task Concurrent Execution Limits concurrentExecLimit limits the number of simultaneous Task executions at any point. Example: If you have 1000 task executions waiting in the queue, and 1000 workers polling this queue for tasks, but if you have set concurrentExecLimit to 10, only 10 tasks would be given to workers (which would lead to starvation). If any of the workers finishes execution, a new task(s) will be removed from the queue, while still keeping the current execution count to 10. Task Rate limits rateLimitFrequencyInSeconds and rateLimitPerFrequency should be used together. rateLimitFrequencyInSeconds sets the \"frequency window\", i.e the duration to be used in events per duration . Eg: 1s, 5s, 60s, 300s etc. rateLimitPerFrequency defines the number of Tasks that can be given to Workers per given \"frequency window\". Example: Let's set rateLimitFrequencyInSeconds = 5 , and rateLimitPerFrequency = 12 . This means, our frequency window is of 5 seconds duration, and for each frequency window, Conductor would only give 12 tasks to workers. So, in a given minute, Conductor would only give 12*(60/5) = 144 tasks to workers irrespective of the number of workers that are polling for the task. Note that unlike concurrentExecLimit , rate limiting doesn't take into account tasks already in progress/completed. Even if all the previous tasks are executed within 1 sec, or would take a few days, the new tasks are still given to workers at configured frequency, 144 tasks per minute in above example. Using inputKeys and outputKeys inputKeys and outputKeys can be considered as parameters and return values for the Task. Consider the task Definition as being represented by an interface: (value1, value2 .. valueN) someTaskDefinition(key1, key2 .. keyN); However, these parameters are not strictly enforced at the moment. Both inputKeys and outputKeys act as a documentation for task re-use. The tasks in workflow need not define all of the keys in the task definition. In the future, this can be extended to be a strict template that all task implementations must adhere to, just like interfaces in programming languages. Using inputTemplate inputTemplate allows to define default values, which can be overridden by values provided in Workflow. Eg: In your Task Definition, you can define your inputTemplate as: inputTemplate : { url : https://some_url:7004 } Now, in your workflow Definition, when using above task, you can use the default url or override with something else in the task's inputParameters . inputParameters : { url : ${workflow.input.some_new_url} }","title":"Task Definition"},{"location":"configuration/taskdef/#task-definition","text":"Conductor maintains a registry of worker tasks. A task MUST be registered before being used in a workflow. Example { name : encode_task , retryCount : 3 , timeoutSeconds : 1200 , inputKeys : [ sourceRequestId , qcElementType ], outputKeys : [ state , skipped , result ], timeoutPolicy : TIME_OUT_WF , retryLogic : FIXED , retryDelaySeconds : 600 , responseTimeoutSeconds : 3600 , concurrentExecLimit : 100 , rateLimitFrequencyInSeconds : 60 , rateLimitPerFrequency : 50 } field description Notes name Task Type. Unique name of the Task that resonates with it's function. Unique description Description of the task optional retryCount No. of retries to attempt when a Task is marked as failure defaults to 3 retryLogic Mechanism for the retries see possible values below retryDelaySeconds Time to wait before retries defaults to 60 seconds timeoutPolicy Task's timeout policy see possible values below timeoutSeconds Time in milliseconds, after which the task is marked as TIMED_OUT if not completed after transitioning to IN_PROGRESS status for the first time No timeouts if set to 0 responseTimeoutSeconds If greater than 0, the task is rescheduled if not updated with a status after this time (heartbeat mechanism). Useful when the worker polls for the task but fails to complete due to errors/network failure. defaults to 0 inputKeys Array of keys of task's expected input. Used for documenting task's input. See Using inputKeys and outputKeys . optional outputKeys Array of keys of task's expected output. Used for documenting task's output optional inputTemplate See Using inputTemplate below. optional concurrentExecLimit Number of tasks that can be executed at any given time. optional rateLimitFrequencyInSeconds, rateLimitPerFrequency See Task Rate limits below. optional","title":"Task Definition"},{"location":"configuration/taskdef/#retry-logic","text":"FIXED : Reschedule the task after the retryDelaySeconds EXPONENTIAL_BACKOFF : reschedule after retryDelaySeconds * attemptNumber","title":"Retry Logic"},{"location":"configuration/taskdef/#timeout-policy","text":"RETRY : Retries the task again TIME_OUT_WF : Workflow is marked as TIMED_OUT and terminated ALERT_ONLY : Registers a counter (task_timeout)","title":"Timeout Policy"},{"location":"configuration/taskdef/#task-concurrent-execution-limits","text":"concurrentExecLimit limits the number of simultaneous Task executions at any point. Example: If you have 1000 task executions waiting in the queue, and 1000 workers polling this queue for tasks, but if you have set concurrentExecLimit to 10, only 10 tasks would be given to workers (which would lead to starvation). If any of the workers finishes execution, a new task(s) will be removed from the queue, while still keeping the current execution count to 10.","title":"Task Concurrent Execution Limits"},{"location":"configuration/taskdef/#task-rate-limits","text":"rateLimitFrequencyInSeconds and rateLimitPerFrequency should be used together. rateLimitFrequencyInSeconds sets the \"frequency window\", i.e the duration to be used in events per duration . Eg: 1s, 5s, 60s, 300s etc. rateLimitPerFrequency defines the number of Tasks that can be given to Workers per given \"frequency window\". Example: Let's set rateLimitFrequencyInSeconds = 5 , and rateLimitPerFrequency = 12 . This means, our frequency window is of 5 seconds duration, and for each frequency window, Conductor would only give 12 tasks to workers. So, in a given minute, Conductor would only give 12*(60/5) = 144 tasks to workers irrespective of the number of workers that are polling for the task. Note that unlike concurrentExecLimit , rate limiting doesn't take into account tasks already in progress/completed. Even if all the previous tasks are executed within 1 sec, or would take a few days, the new tasks are still given to workers at configured frequency, 144 tasks per minute in above example.","title":"Task Rate limits"},{"location":"configuration/taskdef/#using-inputkeys-and-outputkeys","text":"inputKeys and outputKeys can be considered as parameters and return values for the Task. Consider the task Definition as being represented by an interface: (value1, value2 .. valueN) someTaskDefinition(key1, key2 .. keyN); However, these parameters are not strictly enforced at the moment. Both inputKeys and outputKeys act as a documentation for task re-use. The tasks in workflow need not define all of the keys in the task definition. In the future, this can be extended to be a strict template that all task implementations must adhere to, just like interfaces in programming languages.","title":"Using inputKeys and outputKeys"},{"location":"configuration/taskdef/#using-inputtemplate","text":"inputTemplate allows to define default values, which can be overridden by values provided in Workflow. Eg: In your Task Definition, you can define your inputTemplate as: inputTemplate : { url : https://some_url:7004 } Now, in your workflow Definition, when using above task, you can use the default url or override with something else in the task's inputParameters . inputParameters : { url : ${workflow.input.some_new_url} }","title":"Using inputTemplate"},{"location":"configuration/taskdomains/","text":"Task Domains Task domains helps support task development. The idea is same \u201ctask definition\u201d can be implemented in different \u201cdomains\u201d. A domain is some arbitrary name that the developer controls. So when the workflow is started, the caller can specify, out of all the tasks in the workflow, which tasks need to run in a specific domain, this domain is then used to poll for task on the client side to execute it. As an example if a workflow (WF1) has 3 tasks T1, T2, T3. The workflow is deployed and working fine, which means there are T2 workers polling and executing. If you modify T2 and run it locally there is no guarantee that your modified T2 worker will get the task that you are looking for as it coming from the general T2 queue. \u201cTask Domain\u201d feature solves this problem by splitting the T2 queue by domains, so when the app polls for task T2 in a specific domain, it get the correct task. When starting a workflow multiple domains can be specified as a fall backs, for example \"domain1,domain2\". Conductor keeps track of last polling time for each task, so in this case it checks if the there are any active workers for \"domain1\" then the task is put in \"domain1\", if not then the same check is done for the next domain in sequence \"domain2\" and so on. If no workers are active then the task is schedule with no domain (default behavior). Note that this \"fall back\" type domain strings can only be used when starting the workflow, when polling from the client only one domain is used. How to use Task Domains Change the poll call The poll call must now specify the domain. Java Client If you are using the java client then a simple property change will force WorkflowTaskCoordinator to pass the domain to the poller. conductor.worker.T2.domain=mydomain //Task T2 needs to poll for domain mydomain REST call GET /tasks/poll/batch/T2?workerid=myworker domain=mydomain GET /tasks/poll/T2?workerid=myworker domain=mydomain Change the start workflow call When starting the workflow, make sure the task to domain mapping is passes Java Client Map String, Object input = new HashMap (); input.put( wf_input1 , one\u201d); Map String, String taskToDomain = new HashMap (); taskToDomain.put( T2 , mydomain ); // Other options ... // taskToDomain.put( * , mydomain ) will put all tasks in mydomain // taskToDomain.put( T2 , mydomain,fallbackDomain ) If mydomain has no active workers // for T2 then will be put in fallbackDomain. Same can be used with * too. StartWorkflowRequest swr = new StartWorkflowRequest(); swr.withName(\u201cmyWorkflow\u201d) .withCorrelationId(\u201ccorr1\u201d) .withVersion(1) .withInput(input) .withTaskToDomain(taskToDomain); wfclient.startWorkflow(swr); REST call POST /workflow { name : myWorkflow , version : 1 , correlatonId : corr1 input : { wf_input1 : one }, taskToDomain : { T2 : mydomain } }","title":"Task Domains"},{"location":"configuration/taskdomains/#task-domains","text":"Task domains helps support task development. The idea is same \u201ctask definition\u201d can be implemented in different \u201cdomains\u201d. A domain is some arbitrary name that the developer controls. So when the workflow is started, the caller can specify, out of all the tasks in the workflow, which tasks need to run in a specific domain, this domain is then used to poll for task on the client side to execute it. As an example if a workflow (WF1) has 3 tasks T1, T2, T3. The workflow is deployed and working fine, which means there are T2 workers polling and executing. If you modify T2 and run it locally there is no guarantee that your modified T2 worker will get the task that you are looking for as it coming from the general T2 queue. \u201cTask Domain\u201d feature solves this problem by splitting the T2 queue by domains, so when the app polls for task T2 in a specific domain, it get the correct task. When starting a workflow multiple domains can be specified as a fall backs, for example \"domain1,domain2\". Conductor keeps track of last polling time for each task, so in this case it checks if the there are any active workers for \"domain1\" then the task is put in \"domain1\", if not then the same check is done for the next domain in sequence \"domain2\" and so on. If no workers are active then the task is schedule with no domain (default behavior). Note that this \"fall back\" type domain strings can only be used when starting the workflow, when polling from the client only one domain is used.","title":"Task Domains"},{"location":"configuration/taskdomains/#how-to-use-task-domains","text":"","title":"How to use Task Domains"},{"location":"configuration/taskdomains/#change-the-poll-call","text":"The poll call must now specify the domain.","title":"Change the poll call"},{"location":"configuration/taskdomains/#java-client","text":"If you are using the java client then a simple property change will force WorkflowTaskCoordinator to pass the domain to the poller. conductor.worker.T2.domain=mydomain //Task T2 needs to poll for domain mydomain","title":"Java Client"},{"location":"configuration/taskdomains/#rest-call","text":"GET /tasks/poll/batch/T2?workerid=myworker domain=mydomain GET /tasks/poll/T2?workerid=myworker domain=mydomain","title":"REST call"},{"location":"configuration/taskdomains/#change-the-start-workflow-call","text":"When starting the workflow, make sure the task to domain mapping is passes","title":"Change the start workflow call"},{"location":"configuration/taskdomains/#java-client_1","text":"Map String, Object input = new HashMap (); input.put( wf_input1 , one\u201d); Map String, String taskToDomain = new HashMap (); taskToDomain.put( T2 , mydomain ); // Other options ... // taskToDomain.put( * , mydomain ) will put all tasks in mydomain // taskToDomain.put( T2 , mydomain,fallbackDomain ) If mydomain has no active workers // for T2 then will be put in fallbackDomain. Same can be used with * too. StartWorkflowRequest swr = new StartWorkflowRequest(); swr.withName(\u201cmyWorkflow\u201d) .withCorrelationId(\u201ccorr1\u201d) .withVersion(1) .withInput(input) .withTaskToDomain(taskToDomain); wfclient.startWorkflow(swr);","title":"Java Client"},{"location":"configuration/taskdomains/#rest-call_1","text":"POST /workflow { name : myWorkflow , version : 1 , correlatonId : corr1 input : { wf_input1 : one }, taskToDomain : { T2 : mydomain } }","title":"REST call"},{"location":"configuration/workflowdef/","text":"Workflow Definition Workflows are defined using a JSON based DSL. Example { name : encode_and_deploy , description : Encodes a file and deploys to CDN , version : 1 , tasks : [ { name : encode , taskReferenceName : encode , type : SIMPLE , inputParameters : { fileLocation : ${workflow.input.fileLocation} } }, { name : deploy , taskReferenceName : d1 , type : SIMPLE , inputParameters : { fileLocation : ${encode.output.encodeLocation} } } ], outputParameters : { cdn_url : ${d1.output.location} }, failureWorkflow : cleanup_encode_resources , restartable : true , workflowStatusListenerEnabled : true , schemaVersion : 2 } field description Notes name Name of the workflow description Description of the workflow optional version Numeric field used to identify the version of the schema. Use incrementing numbers When starting a workflow execution, if not specified, the definition with highest version is used tasks An array of task definitions as described below. inputParameters List of input parameters. Used for documenting the required inputs to workflow optional outputParameters JSON template used to generate the output of the workflow If not specified, the output is defined as the output of the last executed task failureWorkflow String; Workflow to be run on current Workflow failure. Useful for cleanup or post actions on failure. optional schemaVersion Current Conductor Schema version. schemaVersion 1 is discontinued. Must be 2 restartable Boolean flag to allow Workflow restarts defaults to true workflowStatusListenerEnabled If true, every workflow that gets terminated or completed will send a notification. See below optional (false by default) Tasks within Workflow tasks property in a workflow execution defines an array of tasks to be executed in that order. field description Notes name Name of the task. MUST be registered as a task with Conductor before starting the workflow taskReferenceName Alias used to refer the task within the workflow. MUST be unique within workflow. type Type of task. SIMPLE for tasks executed by remote workers, or one of the system task types description Description of the task optional optional true or false. When set to true - workflow continues even if the task fails. The status of the task is reflected as COMPLETED_WITH_ERRORS Defaults to false inputParameters JSON template that defines the input given to the task See Wiring Inputs and Outputs for details domain See Task Domains for more information. optional In addition to these parameters, System Tasks have their own parameters. Checkout System Tasks for more information. Wiring Inputs and Outputs Workflows are supplied inputs by client when a new execution is triggered. Workflow input is a JSON payload that is available via ${workflow.input...} expressions. Each task in the workflow is given input based on the inputParameters template configured in workflow definition. inputParameters is a JSON fragment with value containing parameters for mapping values from input or output of a workflow or another task during the execution. Syntax for mapping the values follows the pattern as: ${SOURCE.input/output.JSONPath} field description SOURCE can be either \"workflow\" or any of the task reference name input/output refers to either the input or output of the source JSONPath JSON path expression to extract JSON fragment from source's input/output JSON Path Support Conductor supports JSONPath specification and uses Java implementation from here . Example Consider a task with input configured to use input/output parameters from workflow and a task named loc_task . { inputParameters : { movieId : ${workflow.input.movieId} , url : ${workflow.input.fileLocation} , lang : ${loc_task.output.languages[0]} , http_request : { method : POST , url : http://example.com/${loc_task.output.fileId}/encode , body : { recipe : ${workflow.input.recipe} , params : { width : 100 , height : 100 } }, headers : { Accept : application/json , Content-Type : application/json } } } } Consider the following as the workflow input { movieId : movie_123 , fileLocation : s3://moviebucket/file123 , recipe : png } And the output of the loc_task as the following; { fileId : file_xxx_yyy_zzz , languages : [ en , ja , es ] } When scheduling the task, Conductor will merge the values from workflow input and loc_task's output and create the input to the task as follows: { movieId : movie_123 , url : s3://moviebucket/file123 , lang : en , http_request : { method : POST , url : http://example.com/file_xxx_yyy_zzz/encode , body : { recipe : png , params : { width : 100 , height : 100 } }, headers : { Accept : application/json , Content-Type : application/json } } } Workflow notifications Conductor can be configured to publish notifications to external systems upon completion/termination of workflows. See extending conductor for details.","title":"Workflow Definition"},{"location":"configuration/workflowdef/#workflow-definition","text":"Workflows are defined using a JSON based DSL. Example { name : encode_and_deploy , description : Encodes a file and deploys to CDN , version : 1 , tasks : [ { name : encode , taskReferenceName : encode , type : SIMPLE , inputParameters : { fileLocation : ${workflow.input.fileLocation} } }, { name : deploy , taskReferenceName : d1 , type : SIMPLE , inputParameters : { fileLocation : ${encode.output.encodeLocation} } } ], outputParameters : { cdn_url : ${d1.output.location} }, failureWorkflow : cleanup_encode_resources , restartable : true , workflowStatusListenerEnabled : true , schemaVersion : 2 } field description Notes name Name of the workflow description Description of the workflow optional version Numeric field used to identify the version of the schema. Use incrementing numbers When starting a workflow execution, if not specified, the definition with highest version is used tasks An array of task definitions as described below. inputParameters List of input parameters. Used for documenting the required inputs to workflow optional outputParameters JSON template used to generate the output of the workflow If not specified, the output is defined as the output of the last executed task failureWorkflow String; Workflow to be run on current Workflow failure. Useful for cleanup or post actions on failure. optional schemaVersion Current Conductor Schema version. schemaVersion 1 is discontinued. Must be 2 restartable Boolean flag to allow Workflow restarts defaults to true workflowStatusListenerEnabled If true, every workflow that gets terminated or completed will send a notification. See below optional (false by default)","title":"Workflow Definition"},{"location":"configuration/workflowdef/#tasks-within-workflow","text":"tasks property in a workflow execution defines an array of tasks to be executed in that order. field description Notes name Name of the task. MUST be registered as a task with Conductor before starting the workflow taskReferenceName Alias used to refer the task within the workflow. MUST be unique within workflow. type Type of task. SIMPLE for tasks executed by remote workers, or one of the system task types description Description of the task optional optional true or false. When set to true - workflow continues even if the task fails. The status of the task is reflected as COMPLETED_WITH_ERRORS Defaults to false inputParameters JSON template that defines the input given to the task See Wiring Inputs and Outputs for details domain See Task Domains for more information. optional In addition to these parameters, System Tasks have their own parameters. Checkout System Tasks for more information.","title":"Tasks within Workflow"},{"location":"configuration/workflowdef/#wiring-inputs-and-outputs","text":"Workflows are supplied inputs by client when a new execution is triggered. Workflow input is a JSON payload that is available via ${workflow.input...} expressions. Each task in the workflow is given input based on the inputParameters template configured in workflow definition. inputParameters is a JSON fragment with value containing parameters for mapping values from input or output of a workflow or another task during the execution. Syntax for mapping the values follows the pattern as: ${SOURCE.input/output.JSONPath} field description SOURCE can be either \"workflow\" or any of the task reference name input/output refers to either the input or output of the source JSONPath JSON path expression to extract JSON fragment from source's input/output JSON Path Support Conductor supports JSONPath specification and uses Java implementation from here . Example Consider a task with input configured to use input/output parameters from workflow and a task named loc_task . { inputParameters : { movieId : ${workflow.input.movieId} , url : ${workflow.input.fileLocation} , lang : ${loc_task.output.languages[0]} , http_request : { method : POST , url : http://example.com/${loc_task.output.fileId}/encode , body : { recipe : ${workflow.input.recipe} , params : { width : 100 , height : 100 } }, headers : { Accept : application/json , Content-Type : application/json } } } } Consider the following as the workflow input { movieId : movie_123 , fileLocation : s3://moviebucket/file123 , recipe : png } And the output of the loc_task as the following; { fileId : file_xxx_yyy_zzz , languages : [ en , ja , es ] } When scheduling the task, Conductor will merge the values from workflow input and loc_task's output and create the input to the task as follows: { movieId : movie_123 , url : s3://moviebucket/file123 , lang : en , http_request : { method : POST , url : http://example.com/file_xxx_yyy_zzz/encode , body : { recipe : png , params : { width : 100 , height : 100 } }, headers : { Accept : application/json , Content-Type : application/json } } }","title":"Wiring Inputs and Outputs"},{"location":"configuration/workflowdef/#workflow-notifications","text":"Conductor can be configured to publish notifications to external systems upon completion/termination of workflows. See extending conductor for details.","title":"Workflow notifications"},{"location":"gettingstarted/basicconcepts/","text":"Definitions (aka Metadata or Blueprints) Conductor definitions are like class defintions in OOP paradigm, or templates. You define this once, and use for each workflow execution. Definitions to Executions have 1:N relationship. Tasks Tasks are the building blocks of Workflow. There must be at least one task in a Workflow. Tasks can be categorized into two types: Systems tasks - executed by Conductor server. Worker tasks - executed by your own workers. Workflow A Workflow is the container of your process flow. It could include several different types of Tasks, Sub-Workflows, inputs and outputs connected to each other, to effectively achieve the desired result. Workflow Definition Workflows are defined using a JSON based DSL and includes a set of tasks that are executed as part of the workflows. The tasks are either control tasks (fork, conditional etc) or application tasks (e.g. encode a file) that are executed on a remote machine. Detailed description Task Definition Task definitions help define Task level parameters like inputs and outputs, timeouts, retries etc. All tasks need to be registered before they can be used by active workflows. A task can be re-used within multiple workflows. Detailed description System Tasks System tasks are executed within the JVM of the Conductor server and managed by Conductor for its execution and scalability. See Systems tasks for list of available Task types, and instructions for using them. Note Conductor provides an API to create user defined tasks that are executed in the same JVM as the engine. see WorkflowSystemTask interface for details. Worker Tasks Worker tasks are implemented by your application(s) and run in a separate environment from Conductor. The worker tasks can be implemented in any language. These tasks talk to Conductor server via REST/gRPC to poll for tasks and update its status after execution. Worker tasks are identified by task type SIMPLE in the blueprint.","title":"Basic Concepts"},{"location":"gettingstarted/basicconcepts/#definitions-aka-metadata-or-blueprints","text":"Conductor definitions are like class defintions in OOP paradigm, or templates. You define this once, and use for each workflow execution. Definitions to Executions have 1:N relationship.","title":"Definitions (aka Metadata or Blueprints)"},{"location":"gettingstarted/basicconcepts/#tasks","text":"Tasks are the building blocks of Workflow. There must be at least one task in a Workflow. Tasks can be categorized into two types: Systems tasks - executed by Conductor server. Worker tasks - executed by your own workers.","title":"Tasks"},{"location":"gettingstarted/basicconcepts/#workflow","text":"A Workflow is the container of your process flow. It could include several different types of Tasks, Sub-Workflows, inputs and outputs connected to each other, to effectively achieve the desired result.","title":"Workflow"},{"location":"gettingstarted/basicconcepts/#workflow-definition","text":"Workflows are defined using a JSON based DSL and includes a set of tasks that are executed as part of the workflows. The tasks are either control tasks (fork, conditional etc) or application tasks (e.g. encode a file) that are executed on a remote machine. Detailed description","title":"Workflow Definition"},{"location":"gettingstarted/basicconcepts/#task-definition","text":"Task definitions help define Task level parameters like inputs and outputs, timeouts, retries etc. All tasks need to be registered before they can be used by active workflows. A task can be re-used within multiple workflows. Detailed description","title":"Task Definition"},{"location":"gettingstarted/basicconcepts/#system-tasks","text":"System tasks are executed within the JVM of the Conductor server and managed by Conductor for its execution and scalability. See Systems tasks for list of available Task types, and instructions for using them. Note Conductor provides an API to create user defined tasks that are executed in the same JVM as the engine. see WorkflowSystemTask interface for details.","title":"System Tasks"},{"location":"gettingstarted/basicconcepts/#worker-tasks","text":"Worker tasks are implemented by your application(s) and run in a separate environment from Conductor. The worker tasks can be implemented in any language. These tasks talk to Conductor server via REST/gRPC to poll for tasks and update its status after execution. Worker tasks are identified by task type SIMPLE in the blueprint.","title":"Worker Tasks"},{"location":"gettingstarted/client/","text":"Conductor tasks that are executed by remote workers communicate over HTTP endpoints/gRPC to poll for the task and update the status of the execution. Client APIs Conductor provides the following java clients to interact with the various APIs Client Usage Metadata Client Register / Update workflow and task definitions Workflow Client Start a new workflow / Get execution status of a workflow Task Client Poll for task / Update task result after execution / Get status of a task Java Worker Conductor provides a framework to poll for tasks, manage the execution thread and update the status of the execution back to the server. Implement the Worker interface to execute the task. WorkflowTaskCoordinator Manages the task workers thread pool and server communication (poll, task update and ack). The WorkflowTaskCoordinator can be used to register the worker(s) and initialize the polling loop. Use the Builder to create an instance of the WorkflowTaskCoordinator. The builder accepts the following parameters: Parameter Description Default withEurekaClient EurekaClient is used to identify if the server is in discovery or not. When the server goes out of discovery, the polling is stopped. If passed null, discovery check is not done. provided by platform withTaskClient TaskClient used to communicate to the Conductor server (required) withWorkers Workers that will be used for polling work and task execution. (required) withThreadCount Number of threads assigned to the workers. Should be at-least the size of taskWorkers to avoid starvation in a busy system. Number of registered workers withSleepWhenRetry Time in milliseconds, for which the thread should sleep when task update call fails, before retrying the operation. 500 withUpdateRetryCount Number of attempts to be made when updating task status when update status call fails. 3 withWorkerQueueSize Worker queue size for the polled task. 100 withWorkerNamePrefix String prefix that will be used for all the workers. workflow-worker- Once an instance is created, call init() method to initialize the executor service within the coordinator and begin the polling for tasks. Note To ensure that the WorkflowTaskCoordinator stops polling for tasks when the instance becomes unhealthy, call the provided shutdown() hook in a PreDestroy block. Properties The worker behavior can be further controlled by using these properties: Property Type Description Default paused boolean If set to true, the worker stops polling. false pollCount int Number of tasks to poll for in a single poll request. Used for batched polling. Each task will be executed in a separate thread. 1 pollInterval int Interval in milliseconds at which the server should be polled for tasks. 1000 longPollTimeout int Time in milliseconds for long polling to Conductor server for tasks. Use a higher number here as opposed to more frequent polls to reduce excessive calls. 100 Further, these properties can be set either by Worker implementation or by setting the following system properties in the JVM: Name Description conductor.worker. property Applies to ALL the workers in the JVM. conductor.worker. taskDefName . property Applies to the specified worker. Overrides the global property. Examples Sample Worker Implementation Example Python https://github.com/Netflix/conductor/tree/dev/client/python Follow the example as documented in the readme or take a look at kitchensink_workers.py Warning Python client is a community contribution. We encourage you to test it out and let us know the feedback. Pull Requests with fixes or enhancements are welcomed!","title":"Using the Client"},{"location":"gettingstarted/client/#client-apis","text":"Conductor provides the following java clients to interact with the various APIs Client Usage Metadata Client Register / Update workflow and task definitions Workflow Client Start a new workflow / Get execution status of a workflow Task Client Poll for task / Update task result after execution / Get status of a task","title":"Client APIs"},{"location":"gettingstarted/client/#java","text":"","title":"Java"},{"location":"gettingstarted/client/#worker","text":"Conductor provides a framework to poll for tasks, manage the execution thread and update the status of the execution back to the server. Implement the Worker interface to execute the task.","title":"Worker"},{"location":"gettingstarted/client/#workflowtaskcoordinator","text":"Manages the task workers thread pool and server communication (poll, task update and ack). The WorkflowTaskCoordinator can be used to register the worker(s) and initialize the polling loop. Use the Builder to create an instance of the WorkflowTaskCoordinator. The builder accepts the following parameters: Parameter Description Default withEurekaClient EurekaClient is used to identify if the server is in discovery or not. When the server goes out of discovery, the polling is stopped. If passed null, discovery check is not done. provided by platform withTaskClient TaskClient used to communicate to the Conductor server (required) withWorkers Workers that will be used for polling work and task execution. (required) withThreadCount Number of threads assigned to the workers. Should be at-least the size of taskWorkers to avoid starvation in a busy system. Number of registered workers withSleepWhenRetry Time in milliseconds, for which the thread should sleep when task update call fails, before retrying the operation. 500 withUpdateRetryCount Number of attempts to be made when updating task status when update status call fails. 3 withWorkerQueueSize Worker queue size for the polled task. 100 withWorkerNamePrefix String prefix that will be used for all the workers. workflow-worker- Once an instance is created, call init() method to initialize the executor service within the coordinator and begin the polling for tasks. Note To ensure that the WorkflowTaskCoordinator stops polling for tasks when the instance becomes unhealthy, call the provided shutdown() hook in a PreDestroy block. Properties The worker behavior can be further controlled by using these properties: Property Type Description Default paused boolean If set to true, the worker stops polling. false pollCount int Number of tasks to poll for in a single poll request. Used for batched polling. Each task will be executed in a separate thread. 1 pollInterval int Interval in milliseconds at which the server should be polled for tasks. 1000 longPollTimeout int Time in milliseconds for long polling to Conductor server for tasks. Use a higher number here as opposed to more frequent polls to reduce excessive calls. 100 Further, these properties can be set either by Worker implementation or by setting the following system properties in the JVM: Name Description conductor.worker. property Applies to ALL the workers in the JVM. conductor.worker. taskDefName . property Applies to the specified worker. Overrides the global property. Examples Sample Worker Implementation Example","title":"WorkflowTaskCoordinator"},{"location":"gettingstarted/client/#python","text":"https://github.com/Netflix/conductor/tree/dev/client/python Follow the example as documented in the readme or take a look at kitchensink_workers.py Warning Python client is a community contribution. We encourage you to test it out and let us know the feedback. Pull Requests with fixes or enhancements are welcomed!","title":"Python"},{"location":"gettingstarted/startworkflow/","text":"Start Workflow Request When starting a Workflow execution with a registered definition, Workflow accepts following parameters: field description Notes name Name of the Workflow. MUST be registered with Conductor before starting workflow version Workflow version defaults to latest available version input JSON object with key value params, that can be used by downstream tasks See Wiring Inputs and Outputs for details correlationId Unique Id that correlates multiple Workflow executions optional taskToDomain See Task Domains for more information. optional workflowDef Provide adhoc Workflow definition to run, without registering. See Dynamic Workflows below. optional externalInputPayloadStoragePath This is taken care of by Java client. See External Payload Storage for more info. optional Example: Send a POST request to /workflow with payload like: { name : encode_and_deploy , version : 1 , correlationId : my_unique_correlation_id , input : { param1 : value1 , param2 : value2 } } Dynamic Workflows If the need arises to run a one-time workflow, and it doesn't make sense to register Task and Workflow definitions in Conductor Server, as it could change dynamically for each execution, dynamic workflow executions can be used. This enables you to provide a workflow definition embedded with the required task definitions to the Start Workflow Request in the workflowDef parameter, avoiding the need to register the blueprints before execution. Example: Send a POST request to /workflow with payload like: { name : my_adhoc_workflow_notregistered , workflowDef : { ownerApp : my_owner_app , createdBy : my_username , name : my_adhoc_http_test_notregistered , description : Test Http Task Workflow , version : 1 , tasks : [ { name : test_http_task , taskReferenceName : my_test_http_task_registered , inputParameters : { http_request : ${workflow.input.http_request} }, type : HTTP , startDelay : 0 , optional : false } ], schemaVersion : 2 , restartable : true , workflowStatusListenerEnabled : false }, input : { http_request : { uri : /health , vipAddress : cpeworkflow-devint:7004 , method : GET , contentType : application/json , appName : cpeworkflow } } }","title":"Start a Workflow"},{"location":"gettingstarted/startworkflow/#start-workflow-request","text":"When starting a Workflow execution with a registered definition, Workflow accepts following parameters: field description Notes name Name of the Workflow. MUST be registered with Conductor before starting workflow version Workflow version defaults to latest available version input JSON object with key value params, that can be used by downstream tasks See Wiring Inputs and Outputs for details correlationId Unique Id that correlates multiple Workflow executions optional taskToDomain See Task Domains for more information. optional workflowDef Provide adhoc Workflow definition to run, without registering. See Dynamic Workflows below. optional externalInputPayloadStoragePath This is taken care of by Java client. See External Payload Storage for more info. optional Example: Send a POST request to /workflow with payload like: { name : encode_and_deploy , version : 1 , correlationId : my_unique_correlation_id , input : { param1 : value1 , param2 : value2 } }","title":"Start Workflow Request"},{"location":"gettingstarted/startworkflow/#dynamic-workflows","text":"If the need arises to run a one-time workflow, and it doesn't make sense to register Task and Workflow definitions in Conductor Server, as it could change dynamically for each execution, dynamic workflow executions can be used. This enables you to provide a workflow definition embedded with the required task definitions to the Start Workflow Request in the workflowDef parameter, avoiding the need to register the blueprints before execution. Example: Send a POST request to /workflow with payload like: { name : my_adhoc_workflow_notregistered , workflowDef : { ownerApp : my_owner_app , createdBy : my_username , name : my_adhoc_http_test_notregistered , description : Test Http Task Workflow , version : 1 , tasks : [ { name : test_http_task , taskReferenceName : my_test_http_task_registered , inputParameters : { http_request : ${workflow.input.http_request} }, type : HTTP , startDelay : 0 , optional : false } ], schemaVersion : 2 , restartable : true , workflowStatusListenerEnabled : false }, input : { http_request : { uri : /health , vipAddress : cpeworkflow-devint:7004 , method : GET , contentType : application/json , appName : cpeworkflow } } }","title":"Dynamic Workflows"},{"location":"labs/beginner/","text":"Hands on mode Please feel free to follow along using any of these resources: Using cURL. Postman or similar REST client. Creating a Workflow Let's create a simple workflow that adds Netflix Idents to videos. We'll be mocking the adding Idents part and focusing on actually executing this process flow. What are Netflix Idents? Netflix Idents are those 4 second videos with Netflix logo, which appears at the beginning and end of shows. Learn more about them here . You might have also noticed they're different for Animation and several other genres. Disclaimer Obviously, this is not how Netflix adds Idents. Those Workflows are indeed very complex. But, it should give you an idea about how Conductor can be used to implement similar features. The workflow in this lab will look like this: This workflow contains the following: Worker Task verify_if_idents_are_added to verify if Idents are already added. Decision Task that takes output from the previous task, and decides whether to schedule the add_idents task. add_idents task which is another worker Task. Creating Task definitions Let's create the task definition for verify_if_idents_are_added in JSON. This task will be a SIMPLE task which is supposed to be executed by an Idents microservice. We'll be mocking the Idents microservice part. Note that at this point, we don't have to specify whether it is a System task or Worker task. We are only specifying the required configurations for the task, like number of times it should be retried, timeouts etc. We shall start by using name parameter for task name. { name : verify_if_idents_are_added } We'd like this task to be retried 3 times on failure. { name : verify_if_idents_are_added , retryCount : 3 , retryLogic : FIXED , retryDelaySeconds : 10 } And to timeout after 300 seconds. i.e. if the task doesn't finish execution within this time limit after transitioning to IN_PROGRESS state, the Conductor server cancels this task and schedules a new execution of this task in the queue. { name : verify_if_idents_are_added , retryCount : 3 , retryLogic : FIXED , retryDelaySeconds : 10 , timeoutSeconds : 300 , timeoutPolicy : TIME_OUT_WF } And a responseTimeout of 180 seconds. { name : verify_if_idents_are_added , retryCount : 3 , retryLogic : FIXED , retryDelaySeconds : 10 , timeoutSeconds : 300 , timeoutPolicy : TIME_OUT_WF , responseTimeoutSeconds : 180 } We can define several other fields defined here , but this is a good place to start with. Similarly, create another task definition: add_idents . { name : add_idents , retryCount : 3 , retryLogic : FIXED , retryDelaySeconds : 10 , timeoutSeconds : 300 , timeoutPolicy : TIME_OUT_WF , responseTimeoutSeconds : 500 } Send a POST request to /metadata/taskdefs endpoint to register these tasks. You can use Swagger, Postman, CURL or similar tools. Why is the Decision Task not registered? System Tasks that are part of control flow do not need to be registered. However, some system tasks where the retries, rate limiting and other mechanisms are required, like HTTP Task, are to be registered though. Important Task and Workflow Definition names are unique. The names we use below might have already been registered. For this lab, add a prefix with your username, {my_username}_verify_if_idents_are_added for example. This is definitely not recommended for Production usage though. Example curl -X POST \\ http://localhost:8080/api/metadata/taskdefs \\ -H Content-Type: application/json \\ -d [ { name : verify_if_idents_are_added , retryCount : 3, retryLogic : FIXED , retryDelaySeconds : 10, timeoutSeconds : 300, timeoutPolicy : TIME_OUT_WF , responseTimeoutSeconds : 180 }, { name : add_idents , retryCount : 3, retryLogic : FIXED , retryDelaySeconds : 10, timeoutSeconds : 300, timeoutPolicy : TIME_OUT_WF , responseTimeoutSeconds : 180 } ] Creating Workflow Definition Creating Workflow definition is almost similar. We shall use the Task definitions created above. Note that same Task definitions can be used in multiple workflows, or for multipe times in same Workflow (that's where taskReferenceName is useful). A workflow without any tasks looks like this: { name : add_netflix_identation , description : Adds Netflix Identation to video files. , version : 1 , schemaVersion : 2 , tasks : [] } Add the first task that this workflow has to execute. All the tasks must be added to the tasks array. { name : add_netflix_identation , description : Adds Netflix Identation to video files. , version : 1 , schemaVersion : 2 , tasks : [ { name : verify_if_idents_are_added , taskReferenceName : ident_verification , inputParameters : { contentId : ${workflow.input.contentId} }, type : SIMPLE } ] } Wiring Input/Outputs Notice how we were using ${workflow.input.contentId} to pass inputs to this task. Conductor can wire inputs between workflow and tasks, and between tasks. i.e The task verify_if_idents_are_added is wired to accept inputs from the workflow input using JSONPath expression ${workflow.input.param} . Learn more about wiring inputs and outputs here . Let's define decisionCases now. Checkout the Decision task structure here . A Decision task is specified by type:\"DECISION\" , caseValueParam and decisionCases which lists all the branches of Decision task. This is similar to a switch..case but written in Conductor JSON DSL. Adding the decision task: { name : add_netflix_identation , description : Adds Netflix Identation to video files. , version : 2 , schemaVersion : 2 , tasks : [ { name : verify_if_idents_are_added , taskReferenceName : ident_verification , inputParameters : { contentId : ${workflow.input.contentId} }, type : SIMPLE }, { name : decide_task , taskReferenceName : is_idents_added , inputParameters : { case_value_param : ${ident_verification.output.is_idents_added} }, type : DECISION , caseValueParam : case_value_param , decisionCases : { } } ] } Each decision branch could have multiple tasks, so it has to be defined as an array. { name : add_netflix_identation , description : Adds Netflix Identation to video files. , version : 2 , schemaVersion : 2 , tasks : [ { name : verify_if_idents_are_added , taskReferenceName : ident_verification , inputParameters : { contentId : ${workflow.input.contentId} }, type : SIMPLE }, { name : decide_task , taskReferenceName : is_idents_added , inputParameters : { case_value_param : ${ident_verification.output.is_idents_added} }, type : DECISION , caseValueParam : case_value_param , decisionCases : { false : [ { name : add_idents , taskReferenceName : add_idents_by_type , inputParameters : { identType : ${workflow.input.identType} , contentId : ${workflow.input.contentId} }, type : SIMPLE } ] } } ] } Just like the task definitions, register this workflow definition by sending a POST request to /workflow endpoint. Example curl -X POST \\ http://localhost:8080/api/metadata/workflow \\ -H Content-Type: application/json \\ -d { name : add_netflix_identation , description : Adds Netflix Identation to video files. , version : 2, schemaVersion : 2, tasks : [ { name : verify_if_idents_are_added , taskReferenceName : ident_verification , inputParameters : { contentId : ${ workflow . input . contentId } }, type : SIMPLE }, { name : decide_task , taskReferenceName : is_idents_added , inputParameters : { case_value_param : ${ ident_verification . output . is_idents_added } }, type : DECISION , caseValueParam : case_value_param , decisionCases : { false : [ { name : add_idents , taskReferenceName : add_idents_by_type , inputParameters : { identType : ${ workflow . input . identType } , contentId : ${ workflow . input . contentId } }, type : SIMPLE } ] } } ] } Starting the Workflow Send a POST request to /workflow with: { name : add_netflix_identation , version : 2 , correlationId : my_netflix_identation_workflows , input : { identType : animation , contentId : my_unique_content_id } } Example: curl -X POST \\ http://localhost:8080/api/workflow/add_netflix_identation \\ -H Content-Type: application/json \\ -d { identType : animation , contentId : my_unique_content_id } Successful POST request should return a workflow Id, which you can use to find the execution in the UI. Conductor User Interface Open the UI and navigate to the RUNNING tab, the Workflow should be in the state as below: Feel free to explore the various functionalities that the UI exposes. To elaborate on a few: Workflow Task modals (Opens on clicking any of the tasks in the workflow), which includes task I/O, logs and task JSON. Task Details tab, which shows the sequence of task execution, status, start/end time, and link to worker details which executed the task. Input/Output tab shows workflow input and output. Poll for Worker task Now that verify_if_idents_are_added task is in SCHEDULED state, it is the worker's turn to fetch the task, execute it and update Conductor with final status of the task. Ideally, the workers implementing the Client interface would do this process, executing the tasks on real microservices. But, let's mock this part. Send a GET request to /poll endpoint with your task type. For example: curl -X GET \\ http://localhost:8080/api/tasks/poll/verify_if_idents_are_added Ack the Task Let's notify the Conductor server that we have successfully received the task by sending an ACK request with taskId received in the previous step. Otherwise, Conductor would assume that the worker did not receive the task, and requeue it. Send a POST request to /tasks/{taskId}/ack endpoint. Example: curl -X POST \\ http://localhost:8080/api/tasks/{taskId}/ack \\ -H Content-Type: application/json Return response, add logs We can respond to Conductor with any of the following states: Task has COMPLETED. Task has FAILED. Call back after seconds [Process the task at a later time]. Considering our Ident Service has verified that the Ident's are not yet added to given Content Id, let's return the task status by sending the below POST request to /tasks endpoint, with payload: { workflowInstanceId : {workflowId} , taskId : {taskId} , reasonForIncompletion : , callbackAfterSeconds : 0 , workerId : localhost , status : COMPLETED , outputData : { is_idents_added : false } } Example: curl -X POST \\ http://localhost:8080/api/tasks \\ -H Content-Type: application/json \\ -d { workflowInstanceId : cb7c5041-aa85-4940-acb4-3bdcfa9f5c5c , taskId : 741f362b-ee9a-47b6-81b5-9bbbd5c4c992 , reasonForIncompletion : , callbackAfterSeconds : 0, workerId : string , status : COMPLETED , outputData : { is_idents_added : false }, logs : [ { log : Ident verification successful for title: {some_title_name}, with Id: {some_id} , createdTime : 1550178825 } ] } Check logs in UI You can find the logs we just sent by clicking the verify_if_idents_are_added , upon which a modal should open with Logs tab. Why is System task executed, but Worker task is Scheduled. You will notice that Workflow is in the state as below after sending the POST request: Conductor has executed is_idents_added all through it's lifecycle, without us polling, acking, or returning the status of Task. If it is still unclear, is_idents_added is a System task, and System tasks are executed by Conductor Server. But, add_idents is a SIMPLE task. So, the complete lifecyle of this task (Poll, Ack, Update) should be handled by a worker to continue with W\\workflow execution. When Conductor has finished executing all the tasks in given flow, the workflow will reach Terminal state (COMPLETED, FAILED, TIMED_OUT etc.) Next steps You can play around this workflow by failing one of the Tasks, restarting or retrying the Workflow, or by tuning the number of retries, timeoutSeconds etc.","title":"Beginner"},{"location":"labs/beginner/#hands-on-mode","text":"Please feel free to follow along using any of these resources: Using cURL. Postman or similar REST client.","title":"Hands on mode"},{"location":"labs/beginner/#creating-a-workflow","text":"Let's create a simple workflow that adds Netflix Idents to videos. We'll be mocking the adding Idents part and focusing on actually executing this process flow. What are Netflix Idents? Netflix Idents are those 4 second videos with Netflix logo, which appears at the beginning and end of shows. Learn more about them here . You might have also noticed they're different for Animation and several other genres. Disclaimer Obviously, this is not how Netflix adds Idents. Those Workflows are indeed very complex. But, it should give you an idea about how Conductor can be used to implement similar features. The workflow in this lab will look like this: This workflow contains the following: Worker Task verify_if_idents_are_added to verify if Idents are already added. Decision Task that takes output from the previous task, and decides whether to schedule the add_idents task. add_idents task which is another worker Task.","title":"Creating a Workflow"},{"location":"labs/beginner/#creating-task-definitions","text":"Let's create the task definition for verify_if_idents_are_added in JSON. This task will be a SIMPLE task which is supposed to be executed by an Idents microservice. We'll be mocking the Idents microservice part. Note that at this point, we don't have to specify whether it is a System task or Worker task. We are only specifying the required configurations for the task, like number of times it should be retried, timeouts etc. We shall start by using name parameter for task name. { name : verify_if_idents_are_added } We'd like this task to be retried 3 times on failure. { name : verify_if_idents_are_added , retryCount : 3 , retryLogic : FIXED , retryDelaySeconds : 10 } And to timeout after 300 seconds. i.e. if the task doesn't finish execution within this time limit after transitioning to IN_PROGRESS state, the Conductor server cancels this task and schedules a new execution of this task in the queue. { name : verify_if_idents_are_added , retryCount : 3 , retryLogic : FIXED , retryDelaySeconds : 10 , timeoutSeconds : 300 , timeoutPolicy : TIME_OUT_WF } And a responseTimeout of 180 seconds. { name : verify_if_idents_are_added , retryCount : 3 , retryLogic : FIXED , retryDelaySeconds : 10 , timeoutSeconds : 300 , timeoutPolicy : TIME_OUT_WF , responseTimeoutSeconds : 180 } We can define several other fields defined here , but this is a good place to start with. Similarly, create another task definition: add_idents . { name : add_idents , retryCount : 3 , retryLogic : FIXED , retryDelaySeconds : 10 , timeoutSeconds : 300 , timeoutPolicy : TIME_OUT_WF , responseTimeoutSeconds : 500 } Send a POST request to /metadata/taskdefs endpoint to register these tasks. You can use Swagger, Postman, CURL or similar tools. Why is the Decision Task not registered? System Tasks that are part of control flow do not need to be registered. However, some system tasks where the retries, rate limiting and other mechanisms are required, like HTTP Task, are to be registered though. Important Task and Workflow Definition names are unique. The names we use below might have already been registered. For this lab, add a prefix with your username, {my_username}_verify_if_idents_are_added for example. This is definitely not recommended for Production usage though. Example curl -X POST \\ http://localhost:8080/api/metadata/taskdefs \\ -H Content-Type: application/json \\ -d [ { name : verify_if_idents_are_added , retryCount : 3, retryLogic : FIXED , retryDelaySeconds : 10, timeoutSeconds : 300, timeoutPolicy : TIME_OUT_WF , responseTimeoutSeconds : 180 }, { name : add_idents , retryCount : 3, retryLogic : FIXED , retryDelaySeconds : 10, timeoutSeconds : 300, timeoutPolicy : TIME_OUT_WF , responseTimeoutSeconds : 180 } ]","title":"Creating Task definitions"},{"location":"labs/beginner/#creating-workflow-definition","text":"Creating Workflow definition is almost similar. We shall use the Task definitions created above. Note that same Task definitions can be used in multiple workflows, or for multipe times in same Workflow (that's where taskReferenceName is useful). A workflow without any tasks looks like this: { name : add_netflix_identation , description : Adds Netflix Identation to video files. , version : 1 , schemaVersion : 2 , tasks : [] } Add the first task that this workflow has to execute. All the tasks must be added to the tasks array. { name : add_netflix_identation , description : Adds Netflix Identation to video files. , version : 1 , schemaVersion : 2 , tasks : [ { name : verify_if_idents_are_added , taskReferenceName : ident_verification , inputParameters : { contentId : ${workflow.input.contentId} }, type : SIMPLE } ] } Wiring Input/Outputs Notice how we were using ${workflow.input.contentId} to pass inputs to this task. Conductor can wire inputs between workflow and tasks, and between tasks. i.e The task verify_if_idents_are_added is wired to accept inputs from the workflow input using JSONPath expression ${workflow.input.param} . Learn more about wiring inputs and outputs here . Let's define decisionCases now. Checkout the Decision task structure here . A Decision task is specified by type:\"DECISION\" , caseValueParam and decisionCases which lists all the branches of Decision task. This is similar to a switch..case but written in Conductor JSON DSL. Adding the decision task: { name : add_netflix_identation , description : Adds Netflix Identation to video files. , version : 2 , schemaVersion : 2 , tasks : [ { name : verify_if_idents_are_added , taskReferenceName : ident_verification , inputParameters : { contentId : ${workflow.input.contentId} }, type : SIMPLE }, { name : decide_task , taskReferenceName : is_idents_added , inputParameters : { case_value_param : ${ident_verification.output.is_idents_added} }, type : DECISION , caseValueParam : case_value_param , decisionCases : { } } ] } Each decision branch could have multiple tasks, so it has to be defined as an array. { name : add_netflix_identation , description : Adds Netflix Identation to video files. , version : 2 , schemaVersion : 2 , tasks : [ { name : verify_if_idents_are_added , taskReferenceName : ident_verification , inputParameters : { contentId : ${workflow.input.contentId} }, type : SIMPLE }, { name : decide_task , taskReferenceName : is_idents_added , inputParameters : { case_value_param : ${ident_verification.output.is_idents_added} }, type : DECISION , caseValueParam : case_value_param , decisionCases : { false : [ { name : add_idents , taskReferenceName : add_idents_by_type , inputParameters : { identType : ${workflow.input.identType} , contentId : ${workflow.input.contentId} }, type : SIMPLE } ] } } ] } Just like the task definitions, register this workflow definition by sending a POST request to /workflow endpoint. Example curl -X POST \\ http://localhost:8080/api/metadata/workflow \\ -H Content-Type: application/json \\ -d { name : add_netflix_identation , description : Adds Netflix Identation to video files. , version : 2, schemaVersion : 2, tasks : [ { name : verify_if_idents_are_added , taskReferenceName : ident_verification , inputParameters : { contentId : ${ workflow . input . contentId } }, type : SIMPLE }, { name : decide_task , taskReferenceName : is_idents_added , inputParameters : { case_value_param : ${ ident_verification . output . is_idents_added } }, type : DECISION , caseValueParam : case_value_param , decisionCases : { false : [ { name : add_idents , taskReferenceName : add_idents_by_type , inputParameters : { identType : ${ workflow . input . identType } , contentId : ${ workflow . input . contentId } }, type : SIMPLE } ] } } ] }","title":"Creating Workflow Definition"},{"location":"labs/beginner/#starting-the-workflow","text":"Send a POST request to /workflow with: { name : add_netflix_identation , version : 2 , correlationId : my_netflix_identation_workflows , input : { identType : animation , contentId : my_unique_content_id } } Example: curl -X POST \\ http://localhost:8080/api/workflow/add_netflix_identation \\ -H Content-Type: application/json \\ -d { identType : animation , contentId : my_unique_content_id } Successful POST request should return a workflow Id, which you can use to find the execution in the UI.","title":"Starting the Workflow"},{"location":"labs/beginner/#conductor-user-interface","text":"Open the UI and navigate to the RUNNING tab, the Workflow should be in the state as below: Feel free to explore the various functionalities that the UI exposes. To elaborate on a few: Workflow Task modals (Opens on clicking any of the tasks in the workflow), which includes task I/O, logs and task JSON. Task Details tab, which shows the sequence of task execution, status, start/end time, and link to worker details which executed the task. Input/Output tab shows workflow input and output.","title":"Conductor User Interface"},{"location":"labs/beginner/#poll-for-worker-task","text":"Now that verify_if_idents_are_added task is in SCHEDULED state, it is the worker's turn to fetch the task, execute it and update Conductor with final status of the task. Ideally, the workers implementing the Client interface would do this process, executing the tasks on real microservices. But, let's mock this part. Send a GET request to /poll endpoint with your task type. For example: curl -X GET \\ http://localhost:8080/api/tasks/poll/verify_if_idents_are_added","title":"Poll for Worker task"},{"location":"labs/beginner/#ack-the-task","text":"Let's notify the Conductor server that we have successfully received the task by sending an ACK request with taskId received in the previous step. Otherwise, Conductor would assume that the worker did not receive the task, and requeue it. Send a POST request to /tasks/{taskId}/ack endpoint. Example: curl -X POST \\ http://localhost:8080/api/tasks/{taskId}/ack \\ -H Content-Type: application/json","title":"Ack the Task"},{"location":"labs/beginner/#return-response-add-logs","text":"We can respond to Conductor with any of the following states: Task has COMPLETED. Task has FAILED. Call back after seconds [Process the task at a later time]. Considering our Ident Service has verified that the Ident's are not yet added to given Content Id, let's return the task status by sending the below POST request to /tasks endpoint, with payload: { workflowInstanceId : {workflowId} , taskId : {taskId} , reasonForIncompletion : , callbackAfterSeconds : 0 , workerId : localhost , status : COMPLETED , outputData : { is_idents_added : false } } Example: curl -X POST \\ http://localhost:8080/api/tasks \\ -H Content-Type: application/json \\ -d { workflowInstanceId : cb7c5041-aa85-4940-acb4-3bdcfa9f5c5c , taskId : 741f362b-ee9a-47b6-81b5-9bbbd5c4c992 , reasonForIncompletion : , callbackAfterSeconds : 0, workerId : string , status : COMPLETED , outputData : { is_idents_added : false }, logs : [ { log : Ident verification successful for title: {some_title_name}, with Id: {some_id} , createdTime : 1550178825 } ] } Check logs in UI You can find the logs we just sent by clicking the verify_if_idents_are_added , upon which a modal should open with Logs tab.","title":"Return response, add logs"},{"location":"labs/beginner/#why-is-system-task-executed-but-worker-task-is-scheduled","text":"You will notice that Workflow is in the state as below after sending the POST request: Conductor has executed is_idents_added all through it's lifecycle, without us polling, acking, or returning the status of Task. If it is still unclear, is_idents_added is a System task, and System tasks are executed by Conductor Server. But, add_idents is a SIMPLE task. So, the complete lifecyle of this task (Poll, Ack, Update) should be handled by a worker to continue with W\\workflow execution. When Conductor has finished executing all the tasks in given flow, the workflow will reach Terminal state (COMPLETED, FAILED, TIMED_OUT etc.)","title":"Why is System task executed, but Worker task is Scheduled."},{"location":"labs/beginner/#next-steps","text":"You can play around this workflow by failing one of the Tasks, restarting or retrying the Workflow, or by tuning the number of retries, timeoutSeconds etc.","title":"Next steps"},{"location":"labs/eventhandlers/","text":"About In this Lab, we shall: Publish an Event to Conductor using Event task. Subscribe to Events, and perform actions: Start a Workflow Complete Task Conductor Supports Eventing with two Interfaces: Event Task Event Handlers We shall create a simple cyclic workflow similar to this: Create Workflow Definitions Let's create two workflows: test_workflow_for_eventHandler which will have an Event task to start another workflow, and a WAIT System task that will be completed by an event. test_workflow_startedBy_eventHandler which will have an Event task to generate an event to complete WAIT task in the above workflow. Send POST requests to /metadata/workflow endpoint with below payloads: { name : test_workflow_for_eventHandler , description : A test workflow to start another workflow with EventHandler , version : 1 , tasks : [ { name : test_start_workflow_event , taskReferenceName : start_workflow_with_event , type : EVENT , sink : conductor }, { name : test_task_tobe_completed_by_eventHandler , taskReferenceName : test_task_tobe_completed_by_eventHandler , type : WAIT } ] } { name : test_workflow_startedBy_eventHandler , description : A test workflow which is started by EventHandler, and then goes on to complete task in another workflow. , version : 1 , tasks : [ { name : test_complete_task_event , taskReferenceName : complete_task_with_event , inputParameters : { sourceWorkflowId : ${workflow.input.sourceWorkflowId} }, type : EVENT , sink : conductor } ] } Event Tasks in Workflow EVENT task is a System task, and we shall define it just like other Tasks in Workflow, with sink parameter. Also, EVENT task doesn't have to be registered before using in Workflow. This is also true for the WAIT task. Hence, we will not be registering any tasks for these workflows. Events are sent, but they're not handled (yet) Once you try to start test_workflow_for_eventHandler workflow, you would notice that the event is sent successfully, but the second worflow test_workflow_startedBy_eventHandler is not started. We have sent the Events, but we also need to define Event Handlers for Conductor to take any actions based on the Event. Let's create Event Handlers . Create Event Handlers Event Handler definitions are pretty much like Task or Workflow definitions. We start by name: { name : test_start_workflow } Event Handler should know the Queue it has to listen to. This should be defined in event parameter. When using Conductor queues, define event with format: conductor:{workflow_name}:{taskReferenceName} And when using SQS, define with format: sqs:{my_sqs_queue_name} { name : test_start_workflow , event : conductor:test_workflow_for_eventHandler:start_workflow_with_event } Event Handler can perform a list of actions defined in actions array parameter, for this particular event queue. { name : test_start_workflow , event : conductor:test_workflow_for_eventHandler:start_workflow_with_event , actions : [ insert-actions-here ], active : true } Let's define start_workflow action. We shall pass the name of workflow we would like to start. The start_workflow parameter can use any of the values from the general Start Workflow Request . Here we are passing in the workflowId, so that the Complete Task Event Handler can use it. { action : start_workflow , start_workflow : { name : test_workflow_startedBy_eventHandler , input : { sourceWorkflowId : ${workflowInstanceId} } } } Send a POST request to /event endpoint: { name : test_start_workflow , event : conductor:test_workflow_for_eventHandler:start_workflow_with_event , actions : [ { action : start_workflow , start_workflow : { name : test_workflow_startedBy_eventHandler , input : { sourceWorkflowId : ${workflowInstanceId} } } } ], active : true } Similarly, create another Event Handler to complete task. { name : test_complete_task_event , event : conductor:test_workflow_startedBy_eventHandler:complete_task_with_event , actions : [ { action : complete_task , complete_task : { workflowId : ${sourceWorkflowId} , taskRefName : test_task_tobe_completed_by_eventHandler } } ], active : true } Final flow of Workflow After wiring all of the above, starting the test_workflow_for_eventHandler should: Start test_workflow_startedBy_eventHandler workflow. Sets test_task_tobe_completed_by_eventHandler WAIT task IN_PROGRESS . test_workflow_startedBy_eventHandler event task would publish an Event to complete the WAIT task above. Both the workflows would move to COMPLETED state.","title":"Events and Event Handlers"},{"location":"labs/eventhandlers/#about","text":"In this Lab, we shall: Publish an Event to Conductor using Event task. Subscribe to Events, and perform actions: Start a Workflow Complete Task Conductor Supports Eventing with two Interfaces: Event Task Event Handlers We shall create a simple cyclic workflow similar to this:","title":"About"},{"location":"labs/eventhandlers/#create-workflow-definitions","text":"Let's create two workflows: test_workflow_for_eventHandler which will have an Event task to start another workflow, and a WAIT System task that will be completed by an event. test_workflow_startedBy_eventHandler which will have an Event task to generate an event to complete WAIT task in the above workflow. Send POST requests to /metadata/workflow endpoint with below payloads: { name : test_workflow_for_eventHandler , description : A test workflow to start another workflow with EventHandler , version : 1 , tasks : [ { name : test_start_workflow_event , taskReferenceName : start_workflow_with_event , type : EVENT , sink : conductor }, { name : test_task_tobe_completed_by_eventHandler , taskReferenceName : test_task_tobe_completed_by_eventHandler , type : WAIT } ] } { name : test_workflow_startedBy_eventHandler , description : A test workflow which is started by EventHandler, and then goes on to complete task in another workflow. , version : 1 , tasks : [ { name : test_complete_task_event , taskReferenceName : complete_task_with_event , inputParameters : { sourceWorkflowId : ${workflow.input.sourceWorkflowId} }, type : EVENT , sink : conductor } ] }","title":"Create Workflow Definitions"},{"location":"labs/eventhandlers/#event-tasks-in-workflow","text":"EVENT task is a System task, and we shall define it just like other Tasks in Workflow, with sink parameter. Also, EVENT task doesn't have to be registered before using in Workflow. This is also true for the WAIT task. Hence, we will not be registering any tasks for these workflows.","title":"Event Tasks in Workflow"},{"location":"labs/eventhandlers/#events-are-sent-but-theyre-not-handled-yet","text":"Once you try to start test_workflow_for_eventHandler workflow, you would notice that the event is sent successfully, but the second worflow test_workflow_startedBy_eventHandler is not started. We have sent the Events, but we also need to define Event Handlers for Conductor to take any actions based on the Event. Let's create Event Handlers .","title":"Events are sent, but they're not handled (yet)"},{"location":"labs/eventhandlers/#create-event-handlers","text":"Event Handler definitions are pretty much like Task or Workflow definitions. We start by name: { name : test_start_workflow } Event Handler should know the Queue it has to listen to. This should be defined in event parameter. When using Conductor queues, define event with format: conductor:{workflow_name}:{taskReferenceName} And when using SQS, define with format: sqs:{my_sqs_queue_name} { name : test_start_workflow , event : conductor:test_workflow_for_eventHandler:start_workflow_with_event } Event Handler can perform a list of actions defined in actions array parameter, for this particular event queue. { name : test_start_workflow , event : conductor:test_workflow_for_eventHandler:start_workflow_with_event , actions : [ insert-actions-here ], active : true } Let's define start_workflow action. We shall pass the name of workflow we would like to start. The start_workflow parameter can use any of the values from the general Start Workflow Request . Here we are passing in the workflowId, so that the Complete Task Event Handler can use it. { action : start_workflow , start_workflow : { name : test_workflow_startedBy_eventHandler , input : { sourceWorkflowId : ${workflowInstanceId} } } } Send a POST request to /event endpoint: { name : test_start_workflow , event : conductor:test_workflow_for_eventHandler:start_workflow_with_event , actions : [ { action : start_workflow , start_workflow : { name : test_workflow_startedBy_eventHandler , input : { sourceWorkflowId : ${workflowInstanceId} } } } ], active : true } Similarly, create another Event Handler to complete task. { name : test_complete_task_event , event : conductor:test_workflow_startedBy_eventHandler:complete_task_with_event , actions : [ { action : complete_task , complete_task : { workflowId : ${sourceWorkflowId} , taskRefName : test_task_tobe_completed_by_eventHandler } } ], active : true }","title":"Create Event Handlers"},{"location":"labs/eventhandlers/#final-flow-of-workflow","text":"After wiring all of the above, starting the test_workflow_for_eventHandler should: Start test_workflow_startedBy_eventHandler workflow. Sets test_task_tobe_completed_by_eventHandler WAIT task IN_PROGRESS . test_workflow_startedBy_eventHandler event task would publish an Event to complete the WAIT task above. Both the workflows would move to COMPLETED state.","title":"Final flow of Workflow"},{"location":"labs/kitchensink/","text":"An example kitchensink workflow that demonstrates the usage of all the schema constructs. Definition { name : kitchensink , description : kitchensink workflow , version : 1 , tasks : [ { name : task_1 , taskReferenceName : task_1 , inputParameters : { mod : ${workflow.input.mod} , oddEven : ${workflow.input.oddEven} }, type : SIMPLE }, { name : event_task , taskReferenceName : event_0 , inputParameters : { mod : ${workflow.input.mod} , oddEven : ${workflow.input.oddEven} }, type : EVENT , sink : conductor }, { name : dyntask , taskReferenceName : task_2 , inputParameters : { taskToExecute : ${workflow.input.task2Name} }, type : DYNAMIC , dynamicTaskNameParam : taskToExecute }, { name : oddEvenDecision , taskReferenceName : oddEvenDecision , inputParameters : { oddEven : ${task_2.output.oddEven} }, type : DECISION , caseValueParam : oddEven , decisionCases : { 0 : [ { name : task_4 , taskReferenceName : task_4 , inputParameters : { mod : ${task_2.output.mod} , oddEven : ${task_2.output.oddEven} }, type : SIMPLE }, { name : dynamic_fanout , taskReferenceName : fanout1 , inputParameters : { dynamicTasks : ${task_4.output.dynamicTasks} , input : ${task_4.output.inputs} }, type : FORK_JOIN_DYNAMIC , dynamicForkTasksParam : dynamicTasks , dynamicForkTasksInputParamName : input }, { name : dynamic_join , taskReferenceName : join1 , type : JOIN } ], 1 : [ { name : fork_join , taskReferenceName : forkx , type : FORK_JOIN , forkTasks : [ [ { name : task_10 , taskReferenceName : task_10 , type : SIMPLE }, { name : sub_workflow_x , taskReferenceName : wf3 , inputParameters : { mod : ${task_1.output.mod} , oddEven : ${task_1.output.oddEven} }, type : SUB_WORKFLOW , subWorkflowParam : { name : sub_flow_1 , version : 1 } } ], [ { name : task_11 , taskReferenceName : task_11 , type : SIMPLE }, { name : sub_workflow_x , taskReferenceName : wf4 , inputParameters : { mod : ${task_1.output.mod} , oddEven : ${task_1.output.oddEven} }, type : SUB_WORKFLOW , subWorkflowParam : { name : sub_flow_1 , version : 1 } } ] ] }, { name : join , taskReferenceName : join2 , type : JOIN , joinOn : [ wf3 , wf4 ] } ] } }, { name : search_elasticsearch , taskReferenceName : get_es_1 , inputParameters : { http_request : { uri : http://localhost:9200/conductor/_search?size=10 , method : GET } }, type : HTTP }, { name : task_30 , taskReferenceName : task_30 , inputParameters : { statuses : ${get_es_1.output..status} , workflowIds : ${get_es_1.output..workflowId} }, type : SIMPLE } ], outputParameters : { statues : ${get_es_1.output..status} , workflowIds : ${get_es_1.output..workflowId} }, schemaVersion : 2 } Visual Flow Running Kitchensink Workflow Start the server as documented here . Use -DloadSample=true java system property when launching the server. This will create a kitchensink workflow, related task definitions and kick off an instance of kitchensink workflow. Once the workflow has started, the first task remains in the SCHEDULED state. This is because no workers are currently polling for the task. We will use the REST endpoints directly to poll for tasks and updating the status. Start workflow execution Start the execution of the kitchensink workflow by posting the following: curl -X POST --header Content-Type: application/json --header Accept: text/plain http://localhost:8080/api/workflow/kitchensink -d { task2Name : task_5 } The response is a text string identifying the workflow instance id. Poll for the first task: curl http://localhost:8080/api/tasks/poll/task_1 The response should look something like: { taskType : task_1 , status : IN_PROGRESS , inputData : { mod : null , oddEven : null }, referenceTaskName : task_1 , retryCount : 0 , seq : 1 , pollCount : 1 , taskDefName : task_1 , scheduledTime : 1486580932471 , startTime : 1486580933869 , endTime : 0 , updateTime : 1486580933902 , startDelayInSeconds : 0 , retried : false , callbackFromWorker : true , responseTimeoutSeconds : 3600 , workflowInstanceId : b0d1a935-3d74-46fd-92b2-0ca1e388659f , taskId : b9eea7dd-3fbd-46b9-a9ff-b00279459476 , callbackAfterSeconds : 0 , polledTime : 1486580933902 , queueWaitTime : 1398 } Update the task status Note the values for taskId and workflowInstanceId fields from the poll response Update the status of the task as COMPLETED as below: curl -H Content-Type:application/json -H Accept:application/json -X POST http://localhost: 8080 /api/tasks/ -d { taskId : b9eea7dd-3fbd-46b9-a9ff-b00279459476 , workflowInstanceId : b0d1a935-3d74-46fd-92b2-0ca1e388659f , status : COMPLETED , output : { mod : 5 , taskToExecute : task_1 , oddEven : 0 , dynamicTasks : [ { name : task_1 , taskReferenceName : task_1_1 , type : SIMPLE }, { name : sub_workflow_4 , taskReferenceName : wf_dyn , type : SUB_WORKFLOW , subWorkflowParam : { name : sub_flow_1 } } ], inputs : { task_1_1 : {}, wf_dyn : {} } } } This will mark the task_1 as completed and schedule task_5 as the next task. Repeat the same process for the subsequently scheduled tasks until the completion.","title":"Kitchensink"},{"location":"labs/kitchensink/#definition","text":"{ name : kitchensink , description : kitchensink workflow , version : 1 , tasks : [ { name : task_1 , taskReferenceName : task_1 , inputParameters : { mod : ${workflow.input.mod} , oddEven : ${workflow.input.oddEven} }, type : SIMPLE }, { name : event_task , taskReferenceName : event_0 , inputParameters : { mod : ${workflow.input.mod} , oddEven : ${workflow.input.oddEven} }, type : EVENT , sink : conductor }, { name : dyntask , taskReferenceName : task_2 , inputParameters : { taskToExecute : ${workflow.input.task2Name} }, type : DYNAMIC , dynamicTaskNameParam : taskToExecute }, { name : oddEvenDecision , taskReferenceName : oddEvenDecision , inputParameters : { oddEven : ${task_2.output.oddEven} }, type : DECISION , caseValueParam : oddEven , decisionCases : { 0 : [ { name : task_4 , taskReferenceName : task_4 , inputParameters : { mod : ${task_2.output.mod} , oddEven : ${task_2.output.oddEven} }, type : SIMPLE }, { name : dynamic_fanout , taskReferenceName : fanout1 , inputParameters : { dynamicTasks : ${task_4.output.dynamicTasks} , input : ${task_4.output.inputs} }, type : FORK_JOIN_DYNAMIC , dynamicForkTasksParam : dynamicTasks , dynamicForkTasksInputParamName : input }, { name : dynamic_join , taskReferenceName : join1 , type : JOIN } ], 1 : [ { name : fork_join , taskReferenceName : forkx , type : FORK_JOIN , forkTasks : [ [ { name : task_10 , taskReferenceName : task_10 , type : SIMPLE }, { name : sub_workflow_x , taskReferenceName : wf3 , inputParameters : { mod : ${task_1.output.mod} , oddEven : ${task_1.output.oddEven} }, type : SUB_WORKFLOW , subWorkflowParam : { name : sub_flow_1 , version : 1 } } ], [ { name : task_11 , taskReferenceName : task_11 , type : SIMPLE }, { name : sub_workflow_x , taskReferenceName : wf4 , inputParameters : { mod : ${task_1.output.mod} , oddEven : ${task_1.output.oddEven} }, type : SUB_WORKFLOW , subWorkflowParam : { name : sub_flow_1 , version : 1 } } ] ] }, { name : join , taskReferenceName : join2 , type : JOIN , joinOn : [ wf3 , wf4 ] } ] } }, { name : search_elasticsearch , taskReferenceName : get_es_1 , inputParameters : { http_request : { uri : http://localhost:9200/conductor/_search?size=10 , method : GET } }, type : HTTP }, { name : task_30 , taskReferenceName : task_30 , inputParameters : { statuses : ${get_es_1.output..status} , workflowIds : ${get_es_1.output..workflowId} }, type : SIMPLE } ], outputParameters : { statues : ${get_es_1.output..status} , workflowIds : ${get_es_1.output..workflowId} }, schemaVersion : 2 }","title":"Definition"},{"location":"labs/kitchensink/#visual-flow","text":"","title":"Visual Flow"},{"location":"labs/kitchensink/#running-kitchensink-workflow","text":"Start the server as documented here . Use -DloadSample=true java system property when launching the server. This will create a kitchensink workflow, related task definitions and kick off an instance of kitchensink workflow. Once the workflow has started, the first task remains in the SCHEDULED state. This is because no workers are currently polling for the task. We will use the REST endpoints directly to poll for tasks and updating the status.","title":"Running Kitchensink Workflow"},{"location":"labs/kitchensink/#start-workflow-execution","text":"Start the execution of the kitchensink workflow by posting the following: curl -X POST --header Content-Type: application/json --header Accept: text/plain http://localhost:8080/api/workflow/kitchensink -d { task2Name : task_5 } The response is a text string identifying the workflow instance id.","title":"Start workflow execution"},{"location":"labs/kitchensink/#poll-for-the-first-task","text":"curl http://localhost:8080/api/tasks/poll/task_1 The response should look something like: { taskType : task_1 , status : IN_PROGRESS , inputData : { mod : null , oddEven : null }, referenceTaskName : task_1 , retryCount : 0 , seq : 1 , pollCount : 1 , taskDefName : task_1 , scheduledTime : 1486580932471 , startTime : 1486580933869 , endTime : 0 , updateTime : 1486580933902 , startDelayInSeconds : 0 , retried : false , callbackFromWorker : true , responseTimeoutSeconds : 3600 , workflowInstanceId : b0d1a935-3d74-46fd-92b2-0ca1e388659f , taskId : b9eea7dd-3fbd-46b9-a9ff-b00279459476 , callbackAfterSeconds : 0 , polledTime : 1486580933902 , queueWaitTime : 1398 }","title":"Poll for the first task:"},{"location":"labs/kitchensink/#update-the-task-status","text":"Note the values for taskId and workflowInstanceId fields from the poll response Update the status of the task as COMPLETED as below: curl -H Content-Type:application/json -H Accept:application/json -X POST http://localhost: 8080 /api/tasks/ -d { taskId : b9eea7dd-3fbd-46b9-a9ff-b00279459476 , workflowInstanceId : b0d1a935-3d74-46fd-92b2-0ca1e388659f , status : COMPLETED , output : { mod : 5 , taskToExecute : task_1 , oddEven : 0 , dynamicTasks : [ { name : task_1 , taskReferenceName : task_1_1 , type : SIMPLE }, { name : sub_workflow_4 , taskReferenceName : wf_dyn , type : SUB_WORKFLOW , subWorkflowParam : { name : sub_flow_1 } } ], inputs : { task_1_1 : {}, wf_dyn : {} } } } This will mark the task_1 as completed and schedule task_5 as the next task. Repeat the same process for the subsequently scheduled tasks until the completion.","title":"Update the task status"},{"location":"metrics/client/","text":"When using the Java client, the following metrics are published: Name Purpose Tags task_execution_queue_full Counter to record execution queue has saturated taskType task_poll_error Client error when polling for a task queue taskType, includeRetries, status task_paused Counter for number of times the task has been polled, when the worker has been paused taskType task_execute_error Execution error taskType task_ack_failed Task ack failed taskType task_ack_error Task ack has encountered an exception taskType task_update_error Task status cannot be updated back to server taskType task_poll_counter Incremented each time polling is done taskType task_poll_time Time to poll for a batch of tasks taskType task_execute_time Time to execute a task taskType task_result_size Records output payload size of a task taskType workflow_input_size Records input payload size of a workflow workflowType, workflowVersion external_payload_used Incremented each time external payload storage is used name, operation, payloadType Metrics on client side supplements the one collected from server in identifying the network as well as client side issues.","title":"Client Metrics"},{"location":"metrics/server/","text":"Publishing metrics Conductor uses spectator to collect the metrics. To enable conductor serve to publish metrics, add this dependency to your build.gradle. Conductor Server enables you to load additional modules dynamically, this feature can be controlled using this configuration . Create your own AbstractModule that overides configure function and registers the Spectator metrics registry. Initialize the Registry and add it to the global registry via ((CompositeRegistry)Spectator.globalRegistry()).add(...) . The following metrics are published by the server. You can use these metrics to configure alerts for your workflows and tasks. Name Purpose Tags workflow_server_error Rate at which server side error is happening methodName workflow_failure Counter for failing workflows workflowName, status workflow_start_error Counter for failing to start a workflow workflowName workflow_running Counter for no. of running workflows workflowName, version workflow_execution Timer for Workflow completion workflowName, ownerApp task_queue_wait Time spent by a task in queue taskType task_execution Time taken to execute a task taskType, includeRetries, status task_poll Time taken to poll for a task taskType task_poll_count Counter for number of times the task is being polled taskType, domain task_queue_depth Pending tasks queue depth taskType, ownerApp task_rate_limited Current number of tasks being rate limited taskType task_concurrent_execution_limited Current number of tasks being limited by concurrent execution limit taskType task_timeout Counter for timed out tasks taskType task_response_timeout Counter for tasks timedout due to responseTimeout taskType task_update_conflict Counter for task update conflicts. Eg: when the workflow is in terminal state workflowName, taskType, taskStatus, workflowStatus event_queue_messages_processed Counter for number of messages fetched from an event queue queueType, queueName observable_queue_error Counter for number of errors encountered when fetching messages from an event queue queueType event_queue_messages_handled Counter for number of messages executed from an event queue queueType, queueName external_payload_storage_usage Counter for number of times external payload storage was used name, operation, payloadType","title":"Server Metrics"},{"location":"metrics/server/#publishing-metrics","text":"Conductor uses spectator to collect the metrics. To enable conductor serve to publish metrics, add this dependency to your build.gradle. Conductor Server enables you to load additional modules dynamically, this feature can be controlled using this configuration . Create your own AbstractModule that overides configure function and registers the Spectator metrics registry. Initialize the Registry and add it to the global registry via ((CompositeRegistry)Spectator.globalRegistry()).add(...) . The following metrics are published by the server. You can use these metrics to configure alerts for your workflows and tasks. Name Purpose Tags workflow_server_error Rate at which server side error is happening methodName workflow_failure Counter for failing workflows workflowName, status workflow_start_error Counter for failing to start a workflow workflowName workflow_running Counter for no. of running workflows workflowName, version workflow_execution Timer for Workflow completion workflowName, ownerApp task_queue_wait Time spent by a task in queue taskType task_execution Time taken to execute a task taskType, includeRetries, status task_poll Time taken to poll for a task taskType task_poll_count Counter for number of times the task is being polled taskType, domain task_queue_depth Pending tasks queue depth taskType, ownerApp task_rate_limited Current number of tasks being rate limited taskType task_concurrent_execution_limited Current number of tasks being limited by concurrent execution limit taskType task_timeout Counter for timed out tasks taskType task_response_timeout Counter for tasks timedout due to responseTimeout taskType task_update_conflict Counter for task update conflicts. Eg: when the workflow is in terminal state workflowName, taskType, taskStatus, workflowStatus event_queue_messages_processed Counter for number of messages fetched from an event queue queueType, queueName observable_queue_error Counter for number of errors encountered when fetching messages from an event queue queueType event_queue_messages_handled Counter for number of messages executed from an event queue queueType, queueName external_payload_storage_usage Counter for number of times external payload storage was used name, operation, payloadType","title":"Publishing metrics"}]}